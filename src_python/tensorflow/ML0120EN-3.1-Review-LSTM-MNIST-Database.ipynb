{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Big Data University](https://ibm.box.com/shared/static/jvcqp2iy2jlx2b32rmzdt0tx8lvxgzkp.png)\n",
    "# <center> Sequence classification with LSTM on MNIST</center>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font size = 3><strong>In this notebook you will learn the How to use TensorFlow for create a Recurrent Neural Network</strong></font>\n",
    "<br>    \n",
    "- <a href=\"#intro\">Introduction</a>\n",
    "<br>\n",
    "- <p><a href=\"#arch\">Architectures</a></p>\n",
    "    - <a href=\"#lstm\">Long Short-Term Memory Model (LSTM)</a>\n",
    "\n",
    "- <p><a href=\"#build\">Building a LSTM with TensorFlow</a></p>\n",
    "</div>\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"intro\"/> Introduction\n",
    "Recurrent Neural Networks are Deep Learning models with simple structures and a feedback mechanism builted-in, or in different words, the output of a layer is added to the next input and fed back to the same layer.\n",
    "\n",
    "The Recurrent Neural Network is a specialized type of Neural Network that solves the issue of **maintaining context for Sequential data** -- such as Weather data, Stocks, Genes, etc. At each iterative step, the processing unit takes in an input and the current state of the network, and produces an output and a new state that is **re-fed into the network**.\n",
    "\n",
    "However, **this model has some problems**. It's very computationally expensive to maintain the state for a large amount of units, even more so over a long amount of time. Additionally, Recurrent Networks are very sensitive to changes in their parameters. As such, they are prone to different problems with their Gradient Descent optimizer -- they either grow exponentially (Exploding Gradient) or drop down to near zero and stabilize (Vanishing Gradient), both problems that greatly harm a model's learning capability.\n",
    "\n",
    "To solve these problems, Hochreiter and Schmidhuber published a paper in 1997 describing a way to keep information over long periods of time and additionally solve the oversensitivity to parameter changes, i.e., make backpropagating through the Recurrent Networks more viable.\n",
    "\n",
    "(In this notebook, we will cover only LSTM and its implementation using TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"arch\"/>Architectures\n",
    "- Fully Recurrent Network\n",
    "- Recursive Neural Networks\n",
    "- Hopfield Networks\n",
    "- Elman Networks and Jordan Networks\n",
    "- Echo State Networks\n",
    "- Neural history compressor\n",
    "- **The Long Short-Term Memory Model (LSTM)**\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/v7p90neiaqghmpwawpiecmz9n7080m59.png\" alt=\"Representation of a Recurrent Neural Network\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a id=\"lstm\"/>LSTM\n",
    "LSTM is one of the proposed solutions or upgrades to the **Recurrent Neural Network model**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an abstraction of how computer memory works. It is \"bundled\" with whatever processing unit is implemented in the Recurrent Network, although outside of its flow, and is responsible for keeping, reading, and outputting information for the model. The way it works is simple: you have a linear unit, which is the information cell itself, surrounded by three logistic gates responsible for maintaining the data. One gate is for inputting data into the information cell, one is for outputting data from the input cell, and the last one is to keep or forget data depending on the needs of the network.\n",
    "\n",
    "Thanks to that, it not only solves the problem of keeping states, because the network can choose to forget data whenever information is not needed, it also solves the gradient problems, since the Logistic Gates have a very nice derivative.\n",
    "\n",
    "### Long Short-Term Memory Architecture\n",
    "\n",
    "As seen before, the Long Short-Term Memory is composed of a linear unit surrounded by three logistic gates. The name for these gates vary from place to place, but the most usual names for them are:\n",
    "- the \"Input\" or \"Write\" Gate, which handles the writing of data into the information cell, \n",
    "- the \"Output\" or \"Read\" Gate, which handles the sending of data back onto the Recurrent Network, and \n",
    "- the \"Keep\" or \"Forget\" Gate, which handles the maintaining and modification of the data stored in the information cell.\n",
    "\n",
    "<img src=https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png width=\"720\"/>\n",
    "<center>*Diagram of the Long Short-Term Memory Unit*</center>\n",
    "\n",
    "The three gates are the centerpiece of the LSTM unit. The gates, when activated by the network, perform their respective functions. For example, the Input Gate will write whatever data it is passed onto the information cell, the Output Gate will return whatever data is in the information cell, and the Keep Gate will maintain the data in the information cell. These gates are analog and multiplicative, and as such, can modify the data based on the signal they are sent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"build\"/> Building a LSTM with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM for Classification\n",
    "Although RNN is mostly used to model sequences and predict sequential data, we can still classify images using a LSTM network. If we consider every image row as a sequence of pixels, we can feed a LSTM network for classification. Lets use the famous MNIST dataset here. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Dataset\n",
    "\n",
    "Tensor flow already provides **helper functions** to download and process the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **`input_data.read_data_sets(...)`** loads the entire dataset and returns an object **`tensorflow.contrib.learn.python.learn.datasets.mnist.DataSets`**\n",
    "\n",
    "\n",
    "The argument **(`one_hot=False`)** creates the label arrays as 10-dimensional binary vectors (only zeros and ones), in which the index cell for the number one, is the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000 10000 784 10\n",
      "(28, 28) (28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#zg.test\n",
    "trainimgs = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs = mnist.test.images\n",
    "testlabels = mnist.test.labels \n",
    "\n",
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "\n",
    "print ntrain,ntest,dim,nclasses\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0,28,28), np.linspace(0,28,28))\n",
    "\n",
    "print xx.shape,yy.shape\n",
    "#print xx,yy\n",
    "\n",
    "Z =  np.ones(xx.shape)\n",
    "print Z.shape\n",
    "#print Z\n",
    "\n",
    "zx = np.linspace(0,28,28)\n",
    "zy = np.linspace(0,28,28)\n",
    "#print zx.shape,zy.shape\n",
    "#print zx\n",
    "#print xx\n",
    "#zz = [1, 2 ,3]\n",
    "#print zz.shape\n",
    "zimg = testimgs[5].reshape([28,28])\n",
    "print zimg.shape\n",
    "#print zimg\n",
    "zimg1 = zimg.transpose()\n",
    "print zimg1.shape\n",
    "#print zimg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:  (55000, 784)\n",
      "Train Labels   (55000, 10)\n",
      "\n",
      "Test Images:   (10000, 784)\n",
      "Test Labels:   (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "trainimgs = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs = mnist.test.images\n",
    "testlabels = mnist.test.labels \n",
    "\n",
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "print \"Train Images: \", trainimgs.shape\n",
    "print \"Train Labels  \", trainlabels.shape\n",
    "print\n",
    "print \"Test Images:  \" , testimgs.shape\n",
    "print \"Test Labels:  \", testlabels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get one sample, just to understand the structure of MNIST dataset \n",
    "\n",
    "The next code snippet prints the **label vector** (one_hot format), **the class** and actual sample formatted as **image**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADuCAYAAAAp6fzCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5AerhAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112ccb7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1001 - Class: [0] - Label Vector: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.] \n",
      "Sample: 1012 - Class: [7] - Label Vector: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.] \n",
      "Sample: 1033 - Class: [8] - Label Vector: [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.] \n"
     ]
    }
   ],
   "source": [
    "samplesIdx = [1001, 1012, 1033]  #<-- You can change these numbers here to see other samples\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(testimgs[samplesIdx[0]].reshape([28,28]), cmap='gray')\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0,28,28), np.linspace(0,28,28))\n",
    "X =  xx ; Y =  yy\n",
    "Z =  100*np.ones(X.shape)\n",
    "\n",
    "img = testimgs[77].reshape([28,28])\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.set_zlim((0,200))\n",
    "\n",
    "\n",
    "offset=200\n",
    "for i in samplesIdx:\n",
    "    img = testimgs[i].reshape([28,28]).transpose()\n",
    "    ax.contourf(X, Y, img, 200, zdir='z', offset=offset, cmap=\"gray\")\n",
    "    offset -= 100\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in samplesIdx:\n",
    "    print \"Sample: {0} - Class: {1} - Label Vector: {2} \".format(i, np.nonzero(testlabels[i])[0], testlabels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's Understand the parameters, inputs and outputs\n",
    "\n",
    "We will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. \n",
    "\n",
    "#### Our simple RNN consists of  \n",
    "1. One input layer which converts a $28*28$ dimensional input to an $128$ dimensional hidden layer, \n",
    "2. One intermediate recurrent neural network (LSTM) \n",
    "3. One output layer which converts an $128$ dimensional output of the LSTM to $10$ dimensional output indicating a class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input should be a Tensor of shape: [batch_size, time_steps, input_dimension], but in our case it would be (?, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=\"float\", shape=[None, n_steps, n_input], name=\"x\") # Current data input shape: (batch_size, n_steps, n_input) [100x28x28]\n",
    "y = tf.placeholder(dtype=\"float\", shape=[None, n_classes], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create the weight and biases for the read out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a lstm cell with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dynamic_rnn__ creates a recurrent neural network specified from __lstm_cell__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, inputs=x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the rnn would be a [100x28x128] matrix. we use the linear activation to map it to a [?x10 matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tf.reshape(tf.split(outputs, 28, axis=1, num=None, name='split')[-1],[-1,128])\n",
    "pred = tf.matmul(output, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__labels__ and __logits__ should be tensors of shape [100x10], lets check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred ))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the accuracy and evaluation methods to be used in the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just recall that we will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Minibatch Loss= 1.788164, Training Accuracy= 0.38000\n",
      "Iter 2000, Minibatch Loss= 1.642775, Training Accuracy= 0.35000\n",
      "Iter 3000, Minibatch Loss= 1.480977, Training Accuracy= 0.52000\n",
      "Iter 4000, Minibatch Loss= 1.151444, Training Accuracy= 0.57000\n",
      "Iter 5000, Minibatch Loss= 1.033904, Training Accuracy= 0.64000\n",
      "Iter 6000, Minibatch Loss= 0.838453, Training Accuracy= 0.73000\n",
      "Iter 7000, Minibatch Loss= 0.766137, Training Accuracy= 0.74000\n",
      "Iter 8000, Minibatch Loss= 0.588603, Training Accuracy= 0.77000\n",
      "Iter 9000, Minibatch Loss= 0.475881, Training Accuracy= 0.86000\n",
      "Iter 10000, Minibatch Loss= 0.513034, Training Accuracy= 0.85000\n",
      "Iter 11000, Minibatch Loss= 0.486249, Training Accuracy= 0.83000\n",
      "Iter 12000, Minibatch Loss= 0.420098, Training Accuracy= 0.85000\n",
      "Iter 13000, Minibatch Loss= 0.334527, Training Accuracy= 0.89000\n",
      "Iter 14000, Minibatch Loss= 0.368133, Training Accuracy= 0.89000\n",
      "Iter 15000, Minibatch Loss= 0.314631, Training Accuracy= 0.86000\n",
      "Iter 16000, Minibatch Loss= 0.318753, Training Accuracy= 0.91000\n",
      "Iter 17000, Minibatch Loss= 0.412630, Training Accuracy= 0.85000\n",
      "Iter 18000, Minibatch Loss= 0.300319, Training Accuracy= 0.92000\n",
      "Iter 19000, Minibatch Loss= 0.385892, Training Accuracy= 0.89000\n",
      "Iter 20000, Minibatch Loss= 0.283879, Training Accuracy= 0.89000\n",
      "Iter 21000, Minibatch Loss= 0.283496, Training Accuracy= 0.90000\n",
      "Iter 22000, Minibatch Loss= 0.139922, Training Accuracy= 0.96000\n",
      "Iter 23000, Minibatch Loss= 0.334294, Training Accuracy= 0.89000\n",
      "Iter 24000, Minibatch Loss= 0.157980, Training Accuracy= 0.94000\n",
      "Iter 25000, Minibatch Loss= 0.176068, Training Accuracy= 0.93000\n",
      "Iter 26000, Minibatch Loss= 0.206527, Training Accuracy= 0.94000\n",
      "Iter 27000, Minibatch Loss= 0.268582, Training Accuracy= 0.93000\n",
      "Iter 28000, Minibatch Loss= 0.198193, Training Accuracy= 0.92000\n",
      "Iter 29000, Minibatch Loss= 0.156443, Training Accuracy= 0.98000\n",
      "Iter 30000, Minibatch Loss= 0.160976, Training Accuracy= 0.94000\n",
      "Iter 31000, Minibatch Loss= 0.184844, Training Accuracy= 0.94000\n",
      "Iter 32000, Minibatch Loss= 0.292295, Training Accuracy= 0.93000\n",
      "Iter 33000, Minibatch Loss= 0.192629, Training Accuracy= 0.94000\n",
      "Iter 34000, Minibatch Loss= 0.152188, Training Accuracy= 0.96000\n",
      "Iter 35000, Minibatch Loss= 0.242598, Training Accuracy= 0.93000\n",
      "Iter 36000, Minibatch Loss= 0.155779, Training Accuracy= 0.95000\n",
      "Iter 37000, Minibatch Loss= 0.171792, Training Accuracy= 0.92000\n",
      "Iter 38000, Minibatch Loss= 0.115761, Training Accuracy= 0.98000\n",
      "Iter 39000, Minibatch Loss= 0.240806, Training Accuracy= 0.92000\n",
      "Iter 40000, Minibatch Loss= 0.127302, Training Accuracy= 0.95000\n",
      "Iter 41000, Minibatch Loss= 0.172798, Training Accuracy= 0.94000\n",
      "Iter 42000, Minibatch Loss= 0.069711, Training Accuracy= 0.97000\n",
      "Iter 43000, Minibatch Loss= 0.121551, Training Accuracy= 0.99000\n",
      "Iter 44000, Minibatch Loss= 0.114225, Training Accuracy= 0.97000\n",
      "Iter 45000, Minibatch Loss= 0.166929, Training Accuracy= 0.96000\n",
      "Iter 46000, Minibatch Loss= 0.159225, Training Accuracy= 0.95000\n",
      "Iter 47000, Minibatch Loss= 0.105868, Training Accuracy= 0.97000\n",
      "Iter 48000, Minibatch Loss= 0.155194, Training Accuracy= 0.93000\n",
      "Iter 49000, Minibatch Loss= 0.136874, Training Accuracy= 0.96000\n",
      "Iter 50000, Minibatch Loss= 0.112200, Training Accuracy= 0.96000\n",
      "Iter 51000, Minibatch Loss= 0.069883, Training Accuracy= 0.97000\n",
      "Iter 52000, Minibatch Loss= 0.109690, Training Accuracy= 0.96000\n",
      "Iter 53000, Minibatch Loss= 0.144277, Training Accuracy= 0.95000\n",
      "Iter 54000, Minibatch Loss= 0.095041, Training Accuracy= 0.96000\n",
      "Iter 55000, Minibatch Loss= 0.140093, Training Accuracy= 0.98000\n",
      "Iter 56000, Minibatch Loss= 0.170513, Training Accuracy= 0.96000\n",
      "Iter 57000, Minibatch Loss= 0.067359, Training Accuracy= 0.97000\n",
      "Iter 58000, Minibatch Loss= 0.117009, Training Accuracy= 0.97000\n",
      "Iter 59000, Minibatch Loss= 0.129037, Training Accuracy= 0.96000\n",
      "Iter 60000, Minibatch Loss= 0.140900, Training Accuracy= 0.95000\n",
      "Iter 61000, Minibatch Loss= 0.125949, Training Accuracy= 0.96000\n",
      "Iter 62000, Minibatch Loss= 0.075067, Training Accuracy= 0.95000\n",
      "Iter 63000, Minibatch Loss= 0.152816, Training Accuracy= 0.93000\n",
      "Iter 64000, Minibatch Loss= 0.072389, Training Accuracy= 0.98000\n",
      "Iter 65000, Minibatch Loss= 0.070702, Training Accuracy= 0.98000\n",
      "Iter 66000, Minibatch Loss= 0.067393, Training Accuracy= 0.98000\n",
      "Iter 67000, Minibatch Loss= 0.158385, Training Accuracy= 0.94000\n",
      "Iter 68000, Minibatch Loss= 0.128451, Training Accuracy= 0.97000\n",
      "Iter 69000, Minibatch Loss= 0.090171, Training Accuracy= 0.97000\n",
      "Iter 70000, Minibatch Loss= 0.052040, Training Accuracy= 0.98000\n",
      "Iter 71000, Minibatch Loss= 0.097544, Training Accuracy= 0.96000\n",
      "Iter 72000, Minibatch Loss= 0.109802, Training Accuracy= 0.97000\n",
      "Iter 73000, Minibatch Loss= 0.072065, Training Accuracy= 0.97000\n",
      "Iter 74000, Minibatch Loss= 0.121114, Training Accuracy= 0.96000\n",
      "Iter 75000, Minibatch Loss= 0.050750, Training Accuracy= 0.98000\n",
      "Iter 76000, Minibatch Loss= 0.082081, Training Accuracy= 0.97000\n",
      "Iter 77000, Minibatch Loss= 0.118622, Training Accuracy= 0.96000\n",
      "Iter 78000, Minibatch Loss= 0.060676, Training Accuracy= 0.99000\n",
      "Iter 79000, Minibatch Loss= 0.161034, Training Accuracy= 0.97000\n",
      "Iter 80000, Minibatch Loss= 0.123775, Training Accuracy= 0.96000\n",
      "Iter 81000, Minibatch Loss= 0.139391, Training Accuracy= 0.97000\n",
      "Iter 82000, Minibatch Loss= 0.146939, Training Accuracy= 0.95000\n",
      "Iter 83000, Minibatch Loss= 0.071890, Training Accuracy= 0.98000\n",
      "Iter 84000, Minibatch Loss= 0.077522, Training Accuracy= 0.97000\n",
      "Iter 85000, Minibatch Loss= 0.065609, Training Accuracy= 0.99000\n",
      "Iter 86000, Minibatch Loss= 0.040490, Training Accuracy= 0.98000\n",
      "Iter 87000, Minibatch Loss= 0.091244, Training Accuracy= 0.97000\n",
      "Iter 88000, Minibatch Loss= 0.065067, Training Accuracy= 0.97000\n",
      "Iter 89000, Minibatch Loss= 0.081028, Training Accuracy= 0.96000\n",
      "Iter 90000, Minibatch Loss= 0.081185, Training Accuracy= 0.96000\n",
      "Iter 91000, Minibatch Loss= 0.038287, Training Accuracy= 0.99000\n",
      "Iter 92000, Minibatch Loss= 0.083312, Training Accuracy= 0.97000\n",
      "Iter 93000, Minibatch Loss= 0.162638, Training Accuracy= 0.95000\n",
      "Iter 94000, Minibatch Loss= 0.045275, Training Accuracy= 0.98000\n",
      "Iter 95000, Minibatch Loss= 0.049236, Training Accuracy= 0.98000\n",
      "Iter 96000, Minibatch Loss= 0.110074, Training Accuracy= 0.96000\n",
      "Iter 97000, Minibatch Loss= 0.029582, Training Accuracy= 1.00000\n",
      "Iter 98000, Minibatch Loss= 0.133524, Training Accuracy= 0.95000\n",
      "Iter 99000, Minibatch Loss= 0.073151, Training Accuracy= 0.97000\n",
      "Iter 100000, Minibatch Loss= 0.087576, Training Accuracy= 0.95000\n",
      "Iter 101000, Minibatch Loss= 0.041059, Training Accuracy= 0.98000\n",
      "Iter 102000, Minibatch Loss= 0.122938, Training Accuracy= 0.96000\n",
      "Iter 103000, Minibatch Loss= 0.029613, Training Accuracy= 1.00000\n",
      "Iter 104000, Minibatch Loss= 0.170010, Training Accuracy= 0.95000\n",
      "Iter 105000, Minibatch Loss= 0.094354, Training Accuracy= 0.97000\n",
      "Iter 106000, Minibatch Loss= 0.038238, Training Accuracy= 0.99000\n",
      "Iter 107000, Minibatch Loss= 0.107901, Training Accuracy= 0.98000\n",
      "Iter 108000, Minibatch Loss= 0.086505, Training Accuracy= 0.99000\n",
      "Iter 109000, Minibatch Loss= 0.083332, Training Accuracy= 0.97000\n",
      "Iter 110000, Minibatch Loss= 0.082484, Training Accuracy= 0.96000\n",
      "Iter 111000, Minibatch Loss= 0.066015, Training Accuracy= 0.98000\n",
      "Iter 112000, Minibatch Loss= 0.048525, Training Accuracy= 0.97000\n",
      "Iter 113000, Minibatch Loss= 0.116388, Training Accuracy= 0.95000\n",
      "Iter 114000, Minibatch Loss= 0.085674, Training Accuracy= 0.98000\n",
      "Iter 115000, Minibatch Loss= 0.101724, Training Accuracy= 0.97000\n",
      "Iter 116000, Minibatch Loss= 0.135229, Training Accuracy= 0.96000\n",
      "Iter 117000, Minibatch Loss= 0.031581, Training Accuracy= 0.99000\n",
      "Iter 118000, Minibatch Loss= 0.133785, Training Accuracy= 0.95000\n",
      "Iter 119000, Minibatch Loss= 0.048188, Training Accuracy= 0.99000\n",
      "Iter 120000, Minibatch Loss= 0.123756, Training Accuracy= 0.96000\n",
      "Iter 121000, Minibatch Loss= 0.085574, Training Accuracy= 0.98000\n",
      "Iter 122000, Minibatch Loss= 0.055667, Training Accuracy= 0.97000\n",
      "Iter 123000, Minibatch Loss= 0.062188, Training Accuracy= 0.98000\n",
      "Iter 124000, Minibatch Loss= 0.059683, Training Accuracy= 0.99000\n",
      "Iter 125000, Minibatch Loss= 0.150245, Training Accuracy= 0.98000\n",
      "Iter 126000, Minibatch Loss= 0.074086, Training Accuracy= 0.97000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 127000, Minibatch Loss= 0.143947, Training Accuracy= 0.95000\n",
      "Iter 128000, Minibatch Loss= 0.130445, Training Accuracy= 0.98000\n",
      "Iter 129000, Minibatch Loss= 0.031462, Training Accuracy= 0.99000\n",
      "Iter 130000, Minibatch Loss= 0.071769, Training Accuracy= 0.96000\n",
      "Iter 131000, Minibatch Loss= 0.079469, Training Accuracy= 0.98000\n",
      "Iter 132000, Minibatch Loss= 0.048691, Training Accuracy= 0.98000\n",
      "Iter 133000, Minibatch Loss= 0.064300, Training Accuracy= 0.98000\n",
      "Iter 134000, Minibatch Loss= 0.109711, Training Accuracy= 0.97000\n",
      "Iter 135000, Minibatch Loss= 0.080963, Training Accuracy= 0.98000\n",
      "Iter 136000, Minibatch Loss= 0.117963, Training Accuracy= 0.98000\n",
      "Iter 137000, Minibatch Loss= 0.199437, Training Accuracy= 0.95000\n",
      "Iter 138000, Minibatch Loss= 0.060624, Training Accuracy= 0.97000\n",
      "Iter 139000, Minibatch Loss= 0.044635, Training Accuracy= 0.98000\n",
      "Iter 140000, Minibatch Loss= 0.020054, Training Accuracy= 1.00000\n",
      "Iter 141000, Minibatch Loss= 0.043386, Training Accuracy= 0.98000\n",
      "Iter 142000, Minibatch Loss= 0.055500, Training Accuracy= 0.98000\n",
      "Iter 143000, Minibatch Loss= 0.063536, Training Accuracy= 0.99000\n",
      "Iter 144000, Minibatch Loss= 0.100267, Training Accuracy= 0.97000\n",
      "Iter 145000, Minibatch Loss= 0.078541, Training Accuracy= 0.98000\n",
      "Iter 146000, Minibatch Loss= 0.099602, Training Accuracy= 0.97000\n",
      "Iter 147000, Minibatch Loss= 0.017917, Training Accuracy= 0.99000\n",
      "Iter 148000, Minibatch Loss= 0.118611, Training Accuracy= 0.98000\n",
      "Iter 149000, Minibatch Loss= 0.067638, Training Accuracy= 0.99000\n",
      "Iter 150000, Minibatch Loss= 0.108067, Training Accuracy= 0.97000\n",
      "Iter 151000, Minibatch Loss= 0.058493, Training Accuracy= 0.99000\n",
      "Iter 152000, Minibatch Loss= 0.047921, Training Accuracy= 0.98000\n",
      "Iter 153000, Minibatch Loss= 0.057785, Training Accuracy= 0.98000\n",
      "Iter 154000, Minibatch Loss= 0.015240, Training Accuracy= 1.00000\n",
      "Iter 155000, Minibatch Loss= 0.064794, Training Accuracy= 0.98000\n",
      "Iter 156000, Minibatch Loss= 0.057486, Training Accuracy= 0.97000\n",
      "Iter 157000, Minibatch Loss= 0.048755, Training Accuracy= 0.99000\n",
      "Iter 158000, Minibatch Loss= 0.019945, Training Accuracy= 0.99000\n",
      "Iter 159000, Minibatch Loss= 0.017824, Training Accuracy= 1.00000\n",
      "Iter 160000, Minibatch Loss= 0.062764, Training Accuracy= 0.98000\n",
      "Iter 161000, Minibatch Loss= 0.034543, Training Accuracy= 1.00000\n",
      "Iter 162000, Minibatch Loss= 0.036330, Training Accuracy= 0.98000\n",
      "Iter 163000, Minibatch Loss= 0.022196, Training Accuracy= 0.99000\n",
      "Iter 164000, Minibatch Loss= 0.042526, Training Accuracy= 0.99000\n",
      "Iter 165000, Minibatch Loss= 0.090325, Training Accuracy= 0.97000\n",
      "Iter 166000, Minibatch Loss= 0.043603, Training Accuracy= 1.00000\n",
      "Iter 167000, Minibatch Loss= 0.039598, Training Accuracy= 0.98000\n",
      "Iter 168000, Minibatch Loss= 0.019084, Training Accuracy= 1.00000\n",
      "Iter 169000, Minibatch Loss= 0.025492, Training Accuracy= 0.99000\n",
      "Iter 170000, Minibatch Loss= 0.084966, Training Accuracy= 0.98000\n",
      "Iter 171000, Minibatch Loss= 0.020978, Training Accuracy= 0.99000\n",
      "Iter 172000, Minibatch Loss= 0.029527, Training Accuracy= 1.00000\n",
      "Iter 173000, Minibatch Loss= 0.051670, Training Accuracy= 0.98000\n",
      "Iter 174000, Minibatch Loss= 0.034740, Training Accuracy= 0.99000\n",
      "Iter 175000, Minibatch Loss= 0.065309, Training Accuracy= 0.97000\n",
      "Iter 176000, Minibatch Loss= 0.125609, Training Accuracy= 0.96000\n",
      "Iter 177000, Minibatch Loss= 0.121045, Training Accuracy= 0.98000\n",
      "Iter 178000, Minibatch Loss= 0.044984, Training Accuracy= 0.98000\n",
      "Iter 179000, Minibatch Loss= 0.025125, Training Accuracy= 1.00000\n",
      "Iter 180000, Minibatch Loss= 0.030412, Training Accuracy= 0.99000\n",
      "Iter 181000, Minibatch Loss= 0.014479, Training Accuracy= 1.00000\n",
      "Iter 182000, Minibatch Loss= 0.028006, Training Accuracy= 0.98000\n",
      "Iter 183000, Minibatch Loss= 0.019465, Training Accuracy= 1.00000\n",
      "Iter 184000, Minibatch Loss= 0.020453, Training Accuracy= 1.00000\n",
      "Iter 185000, Minibatch Loss= 0.049425, Training Accuracy= 0.99000\n",
      "Iter 186000, Minibatch Loss= 0.088850, Training Accuracy= 0.98000\n",
      "Iter 187000, Minibatch Loss= 0.035702, Training Accuracy= 0.99000\n",
      "Iter 188000, Minibatch Loss= 0.063400, Training Accuracy= 0.99000\n",
      "Iter 189000, Minibatch Loss= 0.056009, Training Accuracy= 0.97000\n",
      "Iter 190000, Minibatch Loss= 0.036608, Training Accuracy= 0.99000\n",
      "Iter 191000, Minibatch Loss= 0.137351, Training Accuracy= 0.97000\n",
      "Iter 192000, Minibatch Loss= 0.044417, Training Accuracy= 0.99000\n",
      "Iter 193000, Minibatch Loss= 0.011389, Training Accuracy= 1.00000\n",
      "Iter 194000, Minibatch Loss= 0.075482, Training Accuracy= 0.99000\n",
      "Iter 195000, Minibatch Loss= 0.075590, Training Accuracy= 0.98000\n",
      "Iter 196000, Minibatch Loss= 0.026211, Training Accuracy= 1.00000\n",
      "Iter 197000, Minibatch Loss= 0.047803, Training Accuracy= 0.98000\n",
      "Iter 198000, Minibatch Loss= 0.065458, Training Accuracy= 0.99000\n",
      "Iter 199000, Minibatch Loss= 0.073839, Training Accuracy= 0.96000\n",
      "Iter 200000, Minibatch Loss= 0.043486, Training Accuracy= 0.99000\n",
      "Iter 201000, Minibatch Loss= 0.022970, Training Accuracy= 1.00000\n",
      "Iter 202000, Minibatch Loss= 0.050736, Training Accuracy= 0.98000\n",
      "Iter 203000, Minibatch Loss= 0.043209, Training Accuracy= 0.99000\n",
      "Iter 204000, Minibatch Loss= 0.024556, Training Accuracy= 0.99000\n",
      "Iter 205000, Minibatch Loss= 0.093361, Training Accuracy= 0.97000\n",
      "Iter 206000, Minibatch Loss= 0.092145, Training Accuracy= 0.97000\n",
      "Iter 207000, Minibatch Loss= 0.033881, Training Accuracy= 0.98000\n",
      "Iter 208000, Minibatch Loss= 0.035133, Training Accuracy= 0.99000\n",
      "Iter 209000, Minibatch Loss= 0.028649, Training Accuracy= 0.99000\n",
      "Iter 210000, Minibatch Loss= 0.099823, Training Accuracy= 0.97000\n",
      "Iter 211000, Minibatch Loss= 0.053625, Training Accuracy= 0.98000\n",
      "Iter 212000, Minibatch Loss= 0.103125, Training Accuracy= 0.97000\n",
      "Iter 213000, Minibatch Loss= 0.040756, Training Accuracy= 0.99000\n",
      "Iter 214000, Minibatch Loss= 0.056289, Training Accuracy= 0.98000\n",
      "Iter 215000, Minibatch Loss= 0.092693, Training Accuracy= 0.98000\n",
      "Iter 216000, Minibatch Loss= 0.074294, Training Accuracy= 0.98000\n",
      "Iter 217000, Minibatch Loss= 0.055347, Training Accuracy= 0.98000\n",
      "Iter 218000, Minibatch Loss= 0.040833, Training Accuracy= 0.99000\n",
      "Iter 219000, Minibatch Loss= 0.011782, Training Accuracy= 1.00000\n",
      "Iter 220000, Minibatch Loss= 0.051265, Training Accuracy= 0.98000\n",
      "Iter 221000, Minibatch Loss= 0.053715, Training Accuracy= 0.98000\n",
      "Iter 222000, Minibatch Loss= 0.029078, Training Accuracy= 0.99000\n",
      "Iter 223000, Minibatch Loss= 0.099047, Training Accuracy= 0.95000\n",
      "Iter 224000, Minibatch Loss= 0.068909, Training Accuracy= 0.97000\n",
      "Iter 225000, Minibatch Loss= 0.049911, Training Accuracy= 0.97000\n",
      "Iter 226000, Minibatch Loss= 0.027503, Training Accuracy= 0.99000\n",
      "Iter 227000, Minibatch Loss= 0.106680, Training Accuracy= 0.97000\n",
      "Iter 228000, Minibatch Loss= 0.044117, Training Accuracy= 0.99000\n",
      "Iter 229000, Minibatch Loss= 0.105458, Training Accuracy= 0.98000\n",
      "Iter 230000, Minibatch Loss= 0.054722, Training Accuracy= 0.98000\n",
      "Iter 231000, Minibatch Loss= 0.022738, Training Accuracy= 0.99000\n",
      "Iter 232000, Minibatch Loss= 0.037182, Training Accuracy= 0.99000\n",
      "Iter 233000, Minibatch Loss= 0.025941, Training Accuracy= 1.00000\n",
      "Iter 234000, Minibatch Loss= 0.022512, Training Accuracy= 1.00000\n",
      "Iter 235000, Minibatch Loss= 0.034076, Training Accuracy= 0.99000\n",
      "Iter 236000, Minibatch Loss= 0.031550, Training Accuracy= 0.98000\n",
      "Iter 237000, Minibatch Loss= 0.031099, Training Accuracy= 0.99000\n",
      "Iter 238000, Minibatch Loss= 0.021598, Training Accuracy= 1.00000\n",
      "Iter 239000, Minibatch Loss= 0.022827, Training Accuracy= 0.99000\n",
      "Iter 240000, Minibatch Loss= 0.040966, Training Accuracy= 0.98000\n",
      "Iter 241000, Minibatch Loss= 0.015485, Training Accuracy= 0.99000\n",
      "Iter 242000, Minibatch Loss= 0.046911, Training Accuracy= 0.98000\n",
      "Iter 243000, Minibatch Loss= 0.073564, Training Accuracy= 0.98000\n",
      "Iter 244000, Minibatch Loss= 0.036462, Training Accuracy= 0.98000\n",
      "Iter 245000, Minibatch Loss= 0.035297, Training Accuracy= 0.99000\n",
      "Iter 246000, Minibatch Loss= 0.067973, Training Accuracy= 0.97000\n",
      "Iter 247000, Minibatch Loss= 0.015885, Training Accuracy= 0.99000\n",
      "Iter 248000, Minibatch Loss= 0.014219, Training Accuracy= 1.00000\n",
      "Iter 249000, Minibatch Loss= 0.028407, Training Accuracy= 0.98000\n",
      "Iter 250000, Minibatch Loss= 0.044556, Training Accuracy= 0.98000\n",
      "Iter 251000, Minibatch Loss= 0.104135, Training Accuracy= 0.97000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 252000, Minibatch Loss= 0.067550, Training Accuracy= 0.97000\n",
      "Iter 253000, Minibatch Loss= 0.014742, Training Accuracy= 1.00000\n",
      "Iter 254000, Minibatch Loss= 0.021625, Training Accuracy= 1.00000\n",
      "Iter 255000, Minibatch Loss= 0.037840, Training Accuracy= 0.98000\n",
      "Iter 256000, Minibatch Loss= 0.056915, Training Accuracy= 0.99000\n",
      "Iter 257000, Minibatch Loss= 0.017101, Training Accuracy= 1.00000\n",
      "Iter 258000, Minibatch Loss= 0.034879, Training Accuracy= 0.99000\n",
      "Iter 259000, Minibatch Loss= 0.082360, Training Accuracy= 0.98000\n",
      "Iter 260000, Minibatch Loss= 0.065729, Training Accuracy= 0.99000\n",
      "Iter 261000, Minibatch Loss= 0.024693, Training Accuracy= 0.99000\n",
      "Iter 262000, Minibatch Loss= 0.021043, Training Accuracy= 1.00000\n",
      "Iter 263000, Minibatch Loss= 0.060383, Training Accuracy= 0.99000\n",
      "Iter 264000, Minibatch Loss= 0.037944, Training Accuracy= 0.99000\n",
      "Iter 265000, Minibatch Loss= 0.015018, Training Accuracy= 1.00000\n",
      "Iter 266000, Minibatch Loss= 0.017189, Training Accuracy= 1.00000\n",
      "Iter 267000, Minibatch Loss= 0.036793, Training Accuracy= 0.99000\n",
      "Iter 268000, Minibatch Loss= 0.020973, Training Accuracy= 0.99000\n",
      "Iter 269000, Minibatch Loss= 0.032616, Training Accuracy= 0.99000\n",
      "Iter 270000, Minibatch Loss= 0.035870, Training Accuracy= 0.99000\n",
      "Iter 271000, Minibatch Loss= 0.040348, Training Accuracy= 0.99000\n",
      "Iter 272000, Minibatch Loss= 0.024830, Training Accuracy= 1.00000\n",
      "Iter 273000, Minibatch Loss= 0.037321, Training Accuracy= 0.99000\n",
      "Iter 274000, Minibatch Loss= 0.067980, Training Accuracy= 0.98000\n",
      "Iter 275000, Minibatch Loss= 0.018427, Training Accuracy= 0.99000\n",
      "Iter 276000, Minibatch Loss= 0.025632, Training Accuracy= 0.98000\n",
      "Iter 277000, Minibatch Loss= 0.007259, Training Accuracy= 1.00000\n",
      "Iter 278000, Minibatch Loss= 0.203627, Training Accuracy= 0.98000\n",
      "Iter 279000, Minibatch Loss= 0.024880, Training Accuracy= 1.00000\n",
      "Iter 280000, Minibatch Loss= 0.039195, Training Accuracy= 0.99000\n",
      "Iter 281000, Minibatch Loss= 0.019051, Training Accuracy= 1.00000\n",
      "Iter 282000, Minibatch Loss= 0.053394, Training Accuracy= 0.98000\n",
      "Iter 283000, Minibatch Loss= 0.017428, Training Accuracy= 1.00000\n",
      "Iter 284000, Minibatch Loss= 0.012667, Training Accuracy= 1.00000\n",
      "Iter 285000, Minibatch Loss= 0.030585, Training Accuracy= 0.98000\n",
      "Iter 286000, Minibatch Loss= 0.060404, Training Accuracy= 0.98000\n",
      "Iter 287000, Minibatch Loss= 0.024065, Training Accuracy= 0.99000\n",
      "Iter 288000, Minibatch Loss= 0.033095, Training Accuracy= 0.99000\n",
      "Iter 289000, Minibatch Loss= 0.037816, Training Accuracy= 1.00000\n",
      "Iter 290000, Minibatch Loss= 0.051662, Training Accuracy= 0.97000\n",
      "Iter 291000, Minibatch Loss= 0.014703, Training Accuracy= 0.99000\n",
      "Iter 292000, Minibatch Loss= 0.030584, Training Accuracy= 0.98000\n",
      "Iter 293000, Minibatch Loss= 0.011069, Training Accuracy= 1.00000\n",
      "Iter 294000, Minibatch Loss= 0.020044, Training Accuracy= 1.00000\n",
      "Iter 295000, Minibatch Loss= 0.011105, Training Accuracy= 1.00000\n",
      "Iter 296000, Minibatch Loss= 0.073333, Training Accuracy= 0.98000\n",
      "Iter 297000, Minibatch Loss= 0.040420, Training Accuracy= 0.99000\n",
      "Iter 298000, Minibatch Loss= 0.054694, Training Accuracy= 0.99000\n",
      "Iter 299000, Minibatch Loss= 0.013285, Training Accuracy= 1.00000\n",
      "Iter 300000, Minibatch Loss= 0.009570, Training Accuracy= 1.00000\n",
      "Iter 301000, Minibatch Loss= 0.036252, Training Accuracy= 0.98000\n",
      "Iter 302000, Minibatch Loss= 0.091157, Training Accuracy= 0.99000\n",
      "Iter 303000, Minibatch Loss= 0.014350, Training Accuracy= 1.00000\n",
      "Iter 304000, Minibatch Loss= 0.050152, Training Accuracy= 0.99000\n",
      "Iter 305000, Minibatch Loss= 0.007263, Training Accuracy= 1.00000\n",
      "Iter 306000, Minibatch Loss= 0.121146, Training Accuracy= 0.96000\n",
      "Iter 307000, Minibatch Loss= 0.044028, Training Accuracy= 0.98000\n",
      "Iter 308000, Minibatch Loss= 0.046797, Training Accuracy= 0.98000\n",
      "Iter 309000, Minibatch Loss= 0.037004, Training Accuracy= 0.99000\n",
      "Iter 310000, Minibatch Loss= 0.047203, Training Accuracy= 0.98000\n",
      "Iter 311000, Minibatch Loss= 0.036451, Training Accuracy= 0.99000\n",
      "Iter 312000, Minibatch Loss= 0.012904, Training Accuracy= 1.00000\n",
      "Iter 313000, Minibatch Loss= 0.023098, Training Accuracy= 1.00000\n",
      "Iter 314000, Minibatch Loss= 0.009035, Training Accuracy= 1.00000\n",
      "Iter 315000, Minibatch Loss= 0.009181, Training Accuracy= 1.00000\n",
      "Iter 316000, Minibatch Loss= 0.008594, Training Accuracy= 1.00000\n",
      "Iter 317000, Minibatch Loss= 0.028022, Training Accuracy= 0.99000\n",
      "Iter 318000, Minibatch Loss= 0.076558, Training Accuracy= 0.98000\n",
      "Iter 319000, Minibatch Loss= 0.013639, Training Accuracy= 0.99000\n",
      "Iter 320000, Minibatch Loss= 0.021458, Training Accuracy= 0.99000\n",
      "Iter 321000, Minibatch Loss= 0.024745, Training Accuracy= 1.00000\n",
      "Iter 322000, Minibatch Loss= 0.021318, Training Accuracy= 0.99000\n",
      "Iter 323000, Minibatch Loss= 0.019088, Training Accuracy= 1.00000\n",
      "Iter 324000, Minibatch Loss= 0.044992, Training Accuracy= 0.98000\n",
      "Iter 325000, Minibatch Loss= 0.018713, Training Accuracy= 1.00000\n",
      "Iter 326000, Minibatch Loss= 0.014290, Training Accuracy= 0.99000\n",
      "Iter 327000, Minibatch Loss= 0.010588, Training Accuracy= 1.00000\n",
      "Iter 328000, Minibatch Loss= 0.024074, Training Accuracy= 0.99000\n",
      "Iter 329000, Minibatch Loss= 0.008700, Training Accuracy= 1.00000\n",
      "Iter 330000, Minibatch Loss= 0.020361, Training Accuracy= 1.00000\n",
      "Iter 331000, Minibatch Loss= 0.033793, Training Accuracy= 0.99000\n",
      "Iter 332000, Minibatch Loss= 0.047250, Training Accuracy= 0.99000\n",
      "Iter 333000, Minibatch Loss= 0.058927, Training Accuracy= 0.99000\n",
      "Iter 334000, Minibatch Loss= 0.014072, Training Accuracy= 1.00000\n",
      "Iter 335000, Minibatch Loss= 0.040627, Training Accuracy= 0.98000\n",
      "Iter 336000, Minibatch Loss= 0.041521, Training Accuracy= 0.98000\n",
      "Iter 337000, Minibatch Loss= 0.022245, Training Accuracy= 0.99000\n",
      "Iter 338000, Minibatch Loss= 0.027477, Training Accuracy= 0.99000\n",
      "Iter 339000, Minibatch Loss= 0.005334, Training Accuracy= 1.00000\n",
      "Iter 340000, Minibatch Loss= 0.010407, Training Accuracy= 1.00000\n",
      "Iter 341000, Minibatch Loss= 0.037612, Training Accuracy= 0.99000\n",
      "Iter 342000, Minibatch Loss= 0.056703, Training Accuracy= 0.98000\n",
      "Iter 343000, Minibatch Loss= 0.003478, Training Accuracy= 1.00000\n",
      "Iter 344000, Minibatch Loss= 0.018598, Training Accuracy= 0.99000\n",
      "Iter 345000, Minibatch Loss= 0.020789, Training Accuracy= 0.99000\n",
      "Iter 346000, Minibatch Loss= 0.043634, Training Accuracy= 0.97000\n",
      "Iter 347000, Minibatch Loss= 0.007588, Training Accuracy= 1.00000\n",
      "Iter 348000, Minibatch Loss= 0.064512, Training Accuracy= 0.99000\n",
      "Iter 349000, Minibatch Loss= 0.012529, Training Accuracy= 0.99000\n",
      "Iter 350000, Minibatch Loss= 0.092708, Training Accuracy= 0.98000\n",
      "Iter 351000, Minibatch Loss= 0.033094, Training Accuracy= 0.99000\n",
      "Iter 352000, Minibatch Loss= 0.008650, Training Accuracy= 1.00000\n",
      "Iter 353000, Minibatch Loss= 0.015171, Training Accuracy= 1.00000\n",
      "Iter 354000, Minibatch Loss= 0.008872, Training Accuracy= 1.00000\n",
      "Iter 355000, Minibatch Loss= 0.052337, Training Accuracy= 0.98000\n",
      "Iter 356000, Minibatch Loss= 0.018254, Training Accuracy= 0.99000\n",
      "Iter 357000, Minibatch Loss= 0.028514, Training Accuracy= 0.98000\n",
      "Iter 358000, Minibatch Loss= 0.013042, Training Accuracy= 1.00000\n",
      "Iter 359000, Minibatch Loss= 0.029333, Training Accuracy= 0.98000\n",
      "Iter 360000, Minibatch Loss= 0.008088, Training Accuracy= 1.00000\n",
      "Iter 361000, Minibatch Loss= 0.004804, Training Accuracy= 1.00000\n",
      "Iter 362000, Minibatch Loss= 0.025830, Training Accuracy= 1.00000\n",
      "Iter 363000, Minibatch Loss= 0.033352, Training Accuracy= 0.98000\n",
      "Iter 364000, Minibatch Loss= 0.021536, Training Accuracy= 1.00000\n",
      "Iter 365000, Minibatch Loss= 0.005634, Training Accuracy= 1.00000\n",
      "Iter 366000, Minibatch Loss= 0.036935, Training Accuracy= 0.99000\n",
      "Iter 367000, Minibatch Loss= 0.021614, Training Accuracy= 1.00000\n",
      "Iter 368000, Minibatch Loss= 0.024915, Training Accuracy= 0.99000\n",
      "Iter 369000, Minibatch Loss= 0.010015, Training Accuracy= 1.00000\n",
      "Iter 370000, Minibatch Loss= 0.047136, Training Accuracy= 0.98000\n",
      "Iter 371000, Minibatch Loss= 0.012129, Training Accuracy= 1.00000\n",
      "Iter 372000, Minibatch Loss= 0.012748, Training Accuracy= 1.00000\n",
      "Iter 373000, Minibatch Loss= 0.006203, Training Accuracy= 1.00000\n",
      "Iter 374000, Minibatch Loss= 0.009385, Training Accuracy= 1.00000\n",
      "Iter 375000, Minibatch Loss= 0.003809, Training Accuracy= 1.00000\n",
      "Iter 376000, Minibatch Loss= 0.027851, Training Accuracy= 0.99000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 377000, Minibatch Loss= 0.041023, Training Accuracy= 0.98000\n",
      "Iter 378000, Minibatch Loss= 0.018724, Training Accuracy= 1.00000\n",
      "Iter 379000, Minibatch Loss= 0.029672, Training Accuracy= 0.99000\n",
      "Iter 380000, Minibatch Loss= 0.052764, Training Accuracy= 0.97000\n",
      "Iter 381000, Minibatch Loss= 0.055858, Training Accuracy= 0.99000\n",
      "Iter 382000, Minibatch Loss= 0.020071, Training Accuracy= 0.99000\n",
      "Iter 383000, Minibatch Loss= 0.030907, Training Accuracy= 0.98000\n",
      "Iter 384000, Minibatch Loss= 0.037582, Training Accuracy= 0.99000\n",
      "Iter 385000, Minibatch Loss= 0.018528, Training Accuracy= 1.00000\n",
      "Iter 386000, Minibatch Loss= 0.025488, Training Accuracy= 0.99000\n",
      "Iter 387000, Minibatch Loss= 0.063016, Training Accuracy= 0.98000\n",
      "Iter 388000, Minibatch Loss= 0.022413, Training Accuracy= 1.00000\n",
      "Iter 389000, Minibatch Loss= 0.014407, Training Accuracy= 0.99000\n",
      "Iter 390000, Minibatch Loss= 0.053278, Training Accuracy= 0.99000\n",
      "Iter 391000, Minibatch Loss= 0.023786, Training Accuracy= 1.00000\n",
      "Iter 392000, Minibatch Loss= 0.034633, Training Accuracy= 0.98000\n",
      "Iter 393000, Minibatch Loss= 0.019568, Training Accuracy= 1.00000\n",
      "Iter 394000, Minibatch Loss= 0.011199, Training Accuracy= 0.99000\n",
      "Iter 395000, Minibatch Loss= 0.007394, Training Accuracy= 1.00000\n",
      "Iter 396000, Minibatch Loss= 0.007605, Training Accuracy= 1.00000\n",
      "Iter 397000, Minibatch Loss= 0.008061, Training Accuracy= 1.00000\n",
      "Iter 398000, Minibatch Loss= 0.006715, Training Accuracy= 1.00000\n",
      "Iter 399000, Minibatch Loss= 0.006631, Training Accuracy= 1.00000\n",
      "Iter 400000, Minibatch Loss= 0.030985, Training Accuracy= 0.99000\n",
      "Iter 401000, Minibatch Loss= 0.008048, Training Accuracy= 1.00000\n",
      "Iter 402000, Minibatch Loss= 0.006861, Training Accuracy= 1.00000\n",
      "Iter 403000, Minibatch Loss= 0.009183, Training Accuracy= 0.99000\n",
      "Iter 404000, Minibatch Loss= 0.007153, Training Accuracy= 1.00000\n",
      "Iter 405000, Minibatch Loss= 0.018142, Training Accuracy= 0.99000\n",
      "Iter 406000, Minibatch Loss= 0.004777, Training Accuracy= 1.00000\n",
      "Iter 407000, Minibatch Loss= 0.124136, Training Accuracy= 0.95000\n",
      "Iter 408000, Minibatch Loss= 0.062813, Training Accuracy= 0.98000\n",
      "Iter 409000, Minibatch Loss= 0.011274, Training Accuracy= 1.00000\n",
      "Iter 410000, Minibatch Loss= 0.033394, Training Accuracy= 0.99000\n",
      "Iter 411000, Minibatch Loss= 0.006584, Training Accuracy= 1.00000\n",
      "Iter 412000, Minibatch Loss= 0.030835, Training Accuracy= 0.99000\n",
      "Iter 413000, Minibatch Loss= 0.008925, Training Accuracy= 1.00000\n",
      "Iter 414000, Minibatch Loss= 0.016885, Training Accuracy= 1.00000\n",
      "Iter 415000, Minibatch Loss= 0.075029, Training Accuracy= 0.99000\n",
      "Iter 416000, Minibatch Loss= 0.017766, Training Accuracy= 0.99000\n",
      "Iter 417000, Minibatch Loss= 0.024118, Training Accuracy= 1.00000\n",
      "Iter 418000, Minibatch Loss= 0.005501, Training Accuracy= 1.00000\n",
      "Iter 419000, Minibatch Loss= 0.007942, Training Accuracy= 1.00000\n",
      "Iter 420000, Minibatch Loss= 0.008845, Training Accuracy= 1.00000\n",
      "Iter 421000, Minibatch Loss= 0.003622, Training Accuracy= 1.00000\n",
      "Iter 422000, Minibatch Loss= 0.026817, Training Accuracy= 0.99000\n",
      "Iter 423000, Minibatch Loss= 0.046501, Training Accuracy= 0.97000\n",
      "Iter 424000, Minibatch Loss= 0.009297, Training Accuracy= 1.00000\n",
      "Iter 425000, Minibatch Loss= 0.041111, Training Accuracy= 0.98000\n",
      "Iter 426000, Minibatch Loss= 0.052183, Training Accuracy= 0.99000\n",
      "Iter 427000, Minibatch Loss= 0.058595, Training Accuracy= 0.98000\n",
      "Iter 428000, Minibatch Loss= 0.052603, Training Accuracy= 0.98000\n",
      "Iter 429000, Minibatch Loss= 0.028793, Training Accuracy= 0.99000\n",
      "Iter 430000, Minibatch Loss= 0.011515, Training Accuracy= 1.00000\n",
      "Iter 431000, Minibatch Loss= 0.011188, Training Accuracy= 1.00000\n",
      "Iter 432000, Minibatch Loss= 0.002868, Training Accuracy= 1.00000\n",
      "Iter 433000, Minibatch Loss= 0.004138, Training Accuracy= 1.00000\n",
      "Iter 434000, Minibatch Loss= 0.021495, Training Accuracy= 1.00000\n",
      "Iter 435000, Minibatch Loss= 0.015527, Training Accuracy= 1.00000\n",
      "Iter 436000, Minibatch Loss= 0.012999, Training Accuracy= 0.99000\n",
      "Iter 437000, Minibatch Loss= 0.014354, Training Accuracy= 1.00000\n",
      "Iter 438000, Minibatch Loss= 0.001366, Training Accuracy= 1.00000\n",
      "Iter 439000, Minibatch Loss= 0.004762, Training Accuracy= 1.00000\n",
      "Iter 440000, Minibatch Loss= 0.033489, Training Accuracy= 0.99000\n",
      "Iter 441000, Minibatch Loss= 0.003236, Training Accuracy= 1.00000\n",
      "Iter 442000, Minibatch Loss= 0.009522, Training Accuracy= 1.00000\n",
      "Iter 443000, Minibatch Loss= 0.005947, Training Accuracy= 1.00000\n",
      "Iter 444000, Minibatch Loss= 0.005490, Training Accuracy= 1.00000\n",
      "Iter 445000, Minibatch Loss= 0.019336, Training Accuracy= 0.99000\n",
      "Iter 446000, Minibatch Loss= 0.005278, Training Accuracy= 1.00000\n",
      "Iter 447000, Minibatch Loss= 0.005359, Training Accuracy= 1.00000\n",
      "Iter 448000, Minibatch Loss= 0.015447, Training Accuracy= 1.00000\n",
      "Iter 449000, Minibatch Loss= 0.033552, Training Accuracy= 0.99000\n",
      "Iter 450000, Minibatch Loss= 0.014563, Training Accuracy= 1.00000\n",
      "Iter 451000, Minibatch Loss= 0.005577, Training Accuracy= 1.00000\n",
      "Iter 452000, Minibatch Loss= 0.005818, Training Accuracy= 1.00000\n",
      "Iter 453000, Minibatch Loss= 0.022901, Training Accuracy= 0.99000\n",
      "Iter 454000, Minibatch Loss= 0.023669, Training Accuracy= 0.99000\n",
      "Iter 455000, Minibatch Loss= 0.009068, Training Accuracy= 1.00000\n",
      "Iter 456000, Minibatch Loss= 0.008788, Training Accuracy= 1.00000\n",
      "Iter 457000, Minibatch Loss= 0.019492, Training Accuracy= 0.99000\n",
      "Iter 458000, Minibatch Loss= 0.005347, Training Accuracy= 1.00000\n",
      "Iter 459000, Minibatch Loss= 0.037783, Training Accuracy= 0.99000\n",
      "Iter 460000, Minibatch Loss= 0.002693, Training Accuracy= 1.00000\n",
      "Iter 461000, Minibatch Loss= 0.017918, Training Accuracy= 1.00000\n",
      "Iter 462000, Minibatch Loss= 0.003586, Training Accuracy= 1.00000\n",
      "Iter 463000, Minibatch Loss= 0.002205, Training Accuracy= 1.00000\n",
      "Iter 464000, Minibatch Loss= 0.065618, Training Accuracy= 0.98000\n",
      "Iter 465000, Minibatch Loss= 0.016800, Training Accuracy= 1.00000\n",
      "Iter 466000, Minibatch Loss= 0.005102, Training Accuracy= 1.00000\n",
      "Iter 467000, Minibatch Loss= 0.010650, Training Accuracy= 1.00000\n",
      "Iter 468000, Minibatch Loss= 0.018646, Training Accuracy= 0.99000\n",
      "Iter 469000, Minibatch Loss= 0.003267, Training Accuracy= 1.00000\n",
      "Iter 470000, Minibatch Loss= 0.013963, Training Accuracy= 1.00000\n",
      "Iter 471000, Minibatch Loss= 0.009700, Training Accuracy= 1.00000\n",
      "Iter 472000, Minibatch Loss= 0.046367, Training Accuracy= 0.97000\n",
      "Iter 473000, Minibatch Loss= 0.016192, Training Accuracy= 1.00000\n",
      "Iter 474000, Minibatch Loss= 0.060365, Training Accuracy= 0.98000\n",
      "Iter 475000, Minibatch Loss= 0.046575, Training Accuracy= 0.99000\n",
      "Iter 476000, Minibatch Loss= 0.023224, Training Accuracy= 1.00000\n",
      "Iter 477000, Minibatch Loss= 0.010843, Training Accuracy= 1.00000\n",
      "Iter 478000, Minibatch Loss= 0.010616, Training Accuracy= 1.00000\n",
      "Iter 479000, Minibatch Loss= 0.058710, Training Accuracy= 0.98000\n",
      "Iter 480000, Minibatch Loss= 0.028176, Training Accuracy= 0.98000\n",
      "Iter 481000, Minibatch Loss= 0.028366, Training Accuracy= 0.99000\n",
      "Iter 482000, Minibatch Loss= 0.006364, Training Accuracy= 1.00000\n",
      "Iter 483000, Minibatch Loss= 0.002601, Training Accuracy= 1.00000\n",
      "Iter 484000, Minibatch Loss= 0.003160, Training Accuracy= 1.00000\n",
      "Iter 485000, Minibatch Loss= 0.007443, Training Accuracy= 1.00000\n",
      "Iter 486000, Minibatch Loss= 0.058697, Training Accuracy= 0.98000\n",
      "Iter 487000, Minibatch Loss= 0.006680, Training Accuracy= 1.00000\n",
      "Iter 488000, Minibatch Loss= 0.045483, Training Accuracy= 0.98000\n",
      "Iter 489000, Minibatch Loss= 0.019315, Training Accuracy= 1.00000\n",
      "Iter 490000, Minibatch Loss= 0.024601, Training Accuracy= 0.99000\n",
      "Iter 491000, Minibatch Loss= 0.014697, Training Accuracy= 0.99000\n",
      "Iter 492000, Minibatch Loss= 0.008693, Training Accuracy= 1.00000\n",
      "Iter 493000, Minibatch Loss= 0.048495, Training Accuracy= 0.99000\n",
      "Iter 494000, Minibatch Loss= 0.020017, Training Accuracy= 1.00000\n",
      "Iter 495000, Minibatch Loss= 0.035338, Training Accuracy= 0.98000\n",
      "Iter 496000, Minibatch Loss= 0.030186, Training Accuracy= 0.99000\n",
      "Iter 497000, Minibatch Loss= 0.005323, Training Accuracy= 1.00000\n",
      "Iter 498000, Minibatch Loss= 0.018823, Training Accuracy= 1.00000\n",
      "Iter 499000, Minibatch Loss= 0.064890, Training Accuracy= 0.98000\n",
      "Iter 500000, Minibatch Loss= 0.017948, Training Accuracy= 1.00000\n",
      "Iter 501000, Minibatch Loss= 0.010826, Training Accuracy= 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 502000, Minibatch Loss= 0.005488, Training Accuracy= 1.00000\n",
      "Iter 503000, Minibatch Loss= 0.003213, Training Accuracy= 1.00000\n",
      "Iter 504000, Minibatch Loss= 0.008634, Training Accuracy= 1.00000\n",
      "Iter 505000, Minibatch Loss= 0.009441, Training Accuracy= 1.00000\n",
      "Iter 506000, Minibatch Loss= 0.004203, Training Accuracy= 1.00000\n",
      "Iter 507000, Minibatch Loss= 0.004509, Training Accuracy= 1.00000\n",
      "Iter 508000, Minibatch Loss= 0.012353, Training Accuracy= 0.99000\n",
      "Iter 509000, Minibatch Loss= 0.003962, Training Accuracy= 1.00000\n",
      "Iter 510000, Minibatch Loss= 0.014468, Training Accuracy= 1.00000\n",
      "Iter 511000, Minibatch Loss= 0.012789, Training Accuracy= 1.00000\n",
      "Iter 512000, Minibatch Loss= 0.011128, Training Accuracy= 1.00000\n",
      "Iter 513000, Minibatch Loss= 0.005980, Training Accuracy= 1.00000\n",
      "Iter 514000, Minibatch Loss= 0.010079, Training Accuracy= 1.00000\n",
      "Iter 515000, Minibatch Loss= 0.007767, Training Accuracy= 1.00000\n",
      "Iter 516000, Minibatch Loss= 0.031221, Training Accuracy= 0.99000\n",
      "Iter 517000, Minibatch Loss= 0.025539, Training Accuracy= 0.99000\n",
      "Iter 518000, Minibatch Loss= 0.007678, Training Accuracy= 1.00000\n",
      "Iter 519000, Minibatch Loss= 0.004674, Training Accuracy= 1.00000\n",
      "Iter 520000, Minibatch Loss= 0.006920, Training Accuracy= 1.00000\n",
      "Iter 521000, Minibatch Loss= 0.001861, Training Accuracy= 1.00000\n",
      "Iter 522000, Minibatch Loss= 0.022012, Training Accuracy= 0.99000\n",
      "Iter 523000, Minibatch Loss= 0.010532, Training Accuracy= 1.00000\n",
      "Iter 524000, Minibatch Loss= 0.003367, Training Accuracy= 1.00000\n",
      "Iter 525000, Minibatch Loss= 0.002651, Training Accuracy= 1.00000\n",
      "Iter 526000, Minibatch Loss= 0.057701, Training Accuracy= 0.98000\n",
      "Iter 527000, Minibatch Loss= 0.001477, Training Accuracy= 1.00000\n",
      "Iter 528000, Minibatch Loss= 0.012025, Training Accuracy= 1.00000\n",
      "Iter 529000, Minibatch Loss= 0.014568, Training Accuracy= 1.00000\n",
      "Iter 530000, Minibatch Loss= 0.007584, Training Accuracy= 1.00000\n",
      "Iter 531000, Minibatch Loss= 0.028808, Training Accuracy= 0.99000\n",
      "Iter 532000, Minibatch Loss= 0.005741, Training Accuracy= 1.00000\n",
      "Iter 533000, Minibatch Loss= 0.004682, Training Accuracy= 1.00000\n",
      "Iter 534000, Minibatch Loss= 0.013531, Training Accuracy= 1.00000\n",
      "Iter 535000, Minibatch Loss= 0.008849, Training Accuracy= 1.00000\n",
      "Iter 536000, Minibatch Loss= 0.039967, Training Accuracy= 0.99000\n",
      "Iter 537000, Minibatch Loss= 0.003053, Training Accuracy= 1.00000\n",
      "Iter 538000, Minibatch Loss= 0.006968, Training Accuracy= 1.00000\n",
      "Iter 539000, Minibatch Loss= 0.013623, Training Accuracy= 1.00000\n",
      "Iter 540000, Minibatch Loss= 0.004856, Training Accuracy= 1.00000\n",
      "Iter 541000, Minibatch Loss= 0.020099, Training Accuracy= 1.00000\n",
      "Iter 542000, Minibatch Loss= 0.012994, Training Accuracy= 1.00000\n",
      "Iter 543000, Minibatch Loss= 0.005484, Training Accuracy= 1.00000\n",
      "Iter 544000, Minibatch Loss= 0.025378, Training Accuracy= 0.98000\n",
      "Iter 545000, Minibatch Loss= 0.001269, Training Accuracy= 1.00000\n",
      "Iter 546000, Minibatch Loss= 0.005797, Training Accuracy= 1.00000\n",
      "Iter 547000, Minibatch Loss= 0.004306, Training Accuracy= 1.00000\n",
      "Iter 548000, Minibatch Loss= 0.000903, Training Accuracy= 1.00000\n",
      "Iter 549000, Minibatch Loss= 0.012769, Training Accuracy= 1.00000\n",
      "Iter 550000, Minibatch Loss= 0.009826, Training Accuracy= 1.00000\n",
      "Iter 551000, Minibatch Loss= 0.024064, Training Accuracy= 0.99000\n",
      "Iter 552000, Minibatch Loss= 0.005403, Training Accuracy= 1.00000\n",
      "Iter 553000, Minibatch Loss= 0.005216, Training Accuracy= 1.00000\n",
      "Iter 554000, Minibatch Loss= 0.045618, Training Accuracy= 0.99000\n",
      "Iter 555000, Minibatch Loss= 0.007062, Training Accuracy= 1.00000\n",
      "Iter 556000, Minibatch Loss= 0.019200, Training Accuracy= 0.99000\n",
      "Iter 557000, Minibatch Loss= 0.032571, Training Accuracy= 0.99000\n",
      "Iter 558000, Minibatch Loss= 0.020553, Training Accuracy= 0.99000\n",
      "Iter 559000, Minibatch Loss= 0.004041, Training Accuracy= 1.00000\n",
      "Iter 560000, Minibatch Loss= 0.045210, Training Accuracy= 0.98000\n",
      "Iter 561000, Minibatch Loss= 0.008047, Training Accuracy= 1.00000\n",
      "Iter 562000, Minibatch Loss= 0.056779, Training Accuracy= 0.99000\n",
      "Iter 563000, Minibatch Loss= 0.011696, Training Accuracy= 1.00000\n",
      "Iter 564000, Minibatch Loss= 0.016730, Training Accuracy= 0.99000\n",
      "Iter 565000, Minibatch Loss= 0.003904, Training Accuracy= 1.00000\n",
      "Iter 566000, Minibatch Loss= 0.020219, Training Accuracy= 1.00000\n",
      "Iter 567000, Minibatch Loss= 0.015870, Training Accuracy= 1.00000\n",
      "Iter 568000, Minibatch Loss= 0.012716, Training Accuracy= 1.00000\n",
      "Iter 569000, Minibatch Loss= 0.000955, Training Accuracy= 1.00000\n",
      "Iter 570000, Minibatch Loss= 0.005524, Training Accuracy= 1.00000\n",
      "Iter 571000, Minibatch Loss= 0.003256, Training Accuracy= 1.00000\n",
      "Iter 572000, Minibatch Loss= 0.004574, Training Accuracy= 1.00000\n",
      "Iter 573000, Minibatch Loss= 0.012150, Training Accuracy= 1.00000\n",
      "Iter 574000, Minibatch Loss= 0.009084, Training Accuracy= 1.00000\n",
      "Iter 575000, Minibatch Loss= 0.114657, Training Accuracy= 0.99000\n",
      "Iter 576000, Minibatch Loss= 0.001411, Training Accuracy= 1.00000\n",
      "Iter 577000, Minibatch Loss= 0.024063, Training Accuracy= 0.99000\n",
      "Iter 578000, Minibatch Loss= 0.007166, Training Accuracy= 1.00000\n",
      "Iter 579000, Minibatch Loss= 0.008799, Training Accuracy= 1.00000\n",
      "Iter 580000, Minibatch Loss= 0.008496, Training Accuracy= 1.00000\n",
      "Iter 581000, Minibatch Loss= 0.006623, Training Accuracy= 1.00000\n",
      "Iter 582000, Minibatch Loss= 0.011103, Training Accuracy= 1.00000\n",
      "Iter 583000, Minibatch Loss= 0.006161, Training Accuracy= 1.00000\n",
      "Iter 584000, Minibatch Loss= 0.011545, Training Accuracy= 1.00000\n",
      "Iter 585000, Minibatch Loss= 0.015827, Training Accuracy= 1.00000\n",
      "Iter 586000, Minibatch Loss= 0.015917, Training Accuracy= 1.00000\n",
      "Iter 587000, Minibatch Loss= 0.016135, Training Accuracy= 0.99000\n",
      "Iter 588000, Minibatch Loss= 0.002227, Training Accuracy= 1.00000\n",
      "Iter 589000, Minibatch Loss= 0.010547, Training Accuracy= 1.00000\n",
      "Iter 590000, Minibatch Loss= 0.013093, Training Accuracy= 1.00000\n",
      "Iter 591000, Minibatch Loss= 0.007012, Training Accuracy= 1.00000\n",
      "Iter 592000, Minibatch Loss= 0.005995, Training Accuracy= 1.00000\n",
      "Iter 593000, Minibatch Loss= 0.020901, Training Accuracy= 0.99000\n",
      "Iter 594000, Minibatch Loss= 0.003582, Training Accuracy= 1.00000\n",
      "Iter 595000, Minibatch Loss= 0.001580, Training Accuracy= 1.00000\n",
      "Iter 596000, Minibatch Loss= 0.019453, Training Accuracy= 1.00000\n",
      "Iter 597000, Minibatch Loss= 0.077106, Training Accuracy= 0.98000\n",
      "Iter 598000, Minibatch Loss= 0.032019, Training Accuracy= 0.99000\n",
      "Iter 599000, Minibatch Loss= 0.038837, Training Accuracy= 0.98000\n",
      "Iter 600000, Minibatch Loss= 0.035446, Training Accuracy= 0.98000\n",
      "Iter 601000, Minibatch Loss= 0.013395, Training Accuracy= 0.99000\n",
      "Iter 602000, Minibatch Loss= 0.033480, Training Accuracy= 0.99000\n",
      "Iter 603000, Minibatch Loss= 0.004984, Training Accuracy= 1.00000\n",
      "Iter 604000, Minibatch Loss= 0.015326, Training Accuracy= 1.00000\n",
      "Iter 605000, Minibatch Loss= 0.010945, Training Accuracy= 1.00000\n",
      "Iter 606000, Minibatch Loss= 0.007916, Training Accuracy= 1.00000\n",
      "Iter 607000, Minibatch Loss= 0.001327, Training Accuracy= 1.00000\n",
      "Iter 608000, Minibatch Loss= 0.003835, Training Accuracy= 1.00000\n",
      "Iter 609000, Minibatch Loss= 0.004849, Training Accuracy= 1.00000\n",
      "Iter 610000, Minibatch Loss= 0.007232, Training Accuracy= 1.00000\n",
      "Iter 611000, Minibatch Loss= 0.028753, Training Accuracy= 0.99000\n",
      "Iter 612000, Minibatch Loss= 0.005529, Training Accuracy= 1.00000\n",
      "Iter 613000, Minibatch Loss= 0.010894, Training Accuracy= 1.00000\n",
      "Iter 614000, Minibatch Loss= 0.017117, Training Accuracy= 0.98000\n",
      "Iter 615000, Minibatch Loss= 0.009434, Training Accuracy= 1.00000\n",
      "Iter 616000, Minibatch Loss= 0.037913, Training Accuracy= 0.99000\n",
      "Iter 617000, Minibatch Loss= 0.002097, Training Accuracy= 1.00000\n",
      "Iter 618000, Minibatch Loss= 0.013555, Training Accuracy= 1.00000\n",
      "Iter 619000, Minibatch Loss= 0.011874, Training Accuracy= 1.00000\n",
      "Iter 620000, Minibatch Loss= 0.002253, Training Accuracy= 1.00000\n",
      "Iter 621000, Minibatch Loss= 0.009270, Training Accuracy= 1.00000\n",
      "Iter 622000, Minibatch Loss= 0.064304, Training Accuracy= 0.99000\n",
      "Iter 623000, Minibatch Loss= 0.012748, Training Accuracy= 0.99000\n",
      "Iter 624000, Minibatch Loss= 0.012120, Training Accuracy= 1.00000\n",
      "Iter 625000, Minibatch Loss= 0.004843, Training Accuracy= 1.00000\n",
      "Iter 626000, Minibatch Loss= 0.003490, Training Accuracy= 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 627000, Minibatch Loss= 0.021444, Training Accuracy= 0.99000\n",
      "Iter 628000, Minibatch Loss= 0.003154, Training Accuracy= 1.00000\n",
      "Iter 629000, Minibatch Loss= 0.006060, Training Accuracy= 1.00000\n",
      "Iter 630000, Minibatch Loss= 0.010135, Training Accuracy= 1.00000\n",
      "Iter 631000, Minibatch Loss= 0.020642, Training Accuracy= 1.00000\n",
      "Iter 632000, Minibatch Loss= 0.011641, Training Accuracy= 1.00000\n",
      "Iter 633000, Minibatch Loss= 0.000406, Training Accuracy= 1.00000\n",
      "Iter 634000, Minibatch Loss= 0.137624, Training Accuracy= 0.98000\n",
      "Iter 635000, Minibatch Loss= 0.026830, Training Accuracy= 0.99000\n",
      "Iter 636000, Minibatch Loss= 0.010098, Training Accuracy= 1.00000\n",
      "Iter 637000, Minibatch Loss= 0.005932, Training Accuracy= 1.00000\n",
      "Iter 638000, Minibatch Loss= 0.012316, Training Accuracy= 0.99000\n",
      "Iter 639000, Minibatch Loss= 0.002846, Training Accuracy= 1.00000\n",
      "Iter 640000, Minibatch Loss= 0.089770, Training Accuracy= 0.98000\n",
      "Iter 641000, Minibatch Loss= 0.005596, Training Accuracy= 1.00000\n",
      "Iter 642000, Minibatch Loss= 0.004360, Training Accuracy= 1.00000\n",
      "Iter 643000, Minibatch Loss= 0.014491, Training Accuracy= 1.00000\n",
      "Iter 644000, Minibatch Loss= 0.002475, Training Accuracy= 1.00000\n",
      "Iter 645000, Minibatch Loss= 0.002622, Training Accuracy= 1.00000\n",
      "Iter 646000, Minibatch Loss= 0.004169, Training Accuracy= 1.00000\n",
      "Iter 647000, Minibatch Loss= 0.019880, Training Accuracy= 1.00000\n",
      "Iter 648000, Minibatch Loss= 0.001602, Training Accuracy= 1.00000\n",
      "Iter 649000, Minibatch Loss= 0.008605, Training Accuracy= 1.00000\n",
      "Iter 650000, Minibatch Loss= 0.009434, Training Accuracy= 1.00000\n",
      "Iter 651000, Minibatch Loss= 0.016097, Training Accuracy= 0.99000\n",
      "Iter 652000, Minibatch Loss= 0.002869, Training Accuracy= 1.00000\n",
      "Iter 653000, Minibatch Loss= 0.006407, Training Accuracy= 1.00000\n",
      "Iter 654000, Minibatch Loss= 0.005956, Training Accuracy= 1.00000\n",
      "Iter 655000, Minibatch Loss= 0.008139, Training Accuracy= 1.00000\n",
      "Iter 656000, Minibatch Loss= 0.016727, Training Accuracy= 0.99000\n",
      "Iter 657000, Minibatch Loss= 0.012303, Training Accuracy= 0.99000\n",
      "Iter 658000, Minibatch Loss= 0.007449, Training Accuracy= 1.00000\n",
      "Iter 659000, Minibatch Loss= 0.006905, Training Accuracy= 1.00000\n",
      "Iter 660000, Minibatch Loss= 0.007406, Training Accuracy= 1.00000\n",
      "Iter 661000, Minibatch Loss= 0.004070, Training Accuracy= 1.00000\n",
      "Iter 662000, Minibatch Loss= 0.003010, Training Accuracy= 1.00000\n",
      "Iter 663000, Minibatch Loss= 0.018640, Training Accuracy= 1.00000\n",
      "Iter 664000, Minibatch Loss= 0.005393, Training Accuracy= 1.00000\n",
      "Iter 665000, Minibatch Loss= 0.012638, Training Accuracy= 0.99000\n",
      "Iter 666000, Minibatch Loss= 0.010096, Training Accuracy= 0.99000\n",
      "Iter 667000, Minibatch Loss= 0.003269, Training Accuracy= 1.00000\n",
      "Iter 668000, Minibatch Loss= 0.027903, Training Accuracy= 0.99000\n",
      "Iter 669000, Minibatch Loss= 0.006874, Training Accuracy= 1.00000\n",
      "Iter 670000, Minibatch Loss= 0.007191, Training Accuracy= 1.00000\n",
      "Iter 671000, Minibatch Loss= 0.008740, Training Accuracy= 1.00000\n",
      "Iter 672000, Minibatch Loss= 0.003554, Training Accuracy= 1.00000\n",
      "Iter 673000, Minibatch Loss= 0.022780, Training Accuracy= 0.99000\n",
      "Iter 674000, Minibatch Loss= 0.003321, Training Accuracy= 1.00000\n",
      "Iter 675000, Minibatch Loss= 0.005043, Training Accuracy= 1.00000\n",
      "Iter 676000, Minibatch Loss= 0.006977, Training Accuracy= 1.00000\n",
      "Iter 677000, Minibatch Loss= 0.006702, Training Accuracy= 1.00000\n",
      "Iter 678000, Minibatch Loss= 0.003979, Training Accuracy= 1.00000\n",
      "Iter 679000, Minibatch Loss= 0.007509, Training Accuracy= 1.00000\n",
      "Iter 680000, Minibatch Loss= 0.011496, Training Accuracy= 1.00000\n",
      "Iter 681000, Minibatch Loss= 0.002694, Training Accuracy= 1.00000\n",
      "Iter 682000, Minibatch Loss= 0.002067, Training Accuracy= 1.00000\n",
      "Iter 683000, Minibatch Loss= 0.002833, Training Accuracy= 1.00000\n",
      "Iter 684000, Minibatch Loss= 0.007309, Training Accuracy= 1.00000\n",
      "Iter 685000, Minibatch Loss= 0.008687, Training Accuracy= 1.00000\n",
      "Iter 686000, Minibatch Loss= 0.003420, Training Accuracy= 1.00000\n",
      "Iter 687000, Minibatch Loss= 0.026508, Training Accuracy= 0.99000\n",
      "Iter 688000, Minibatch Loss= 0.022652, Training Accuracy= 0.99000\n",
      "Iter 689000, Minibatch Loss= 0.080039, Training Accuracy= 0.99000\n",
      "Iter 690000, Minibatch Loss= 0.004157, Training Accuracy= 1.00000\n",
      "Iter 691000, Minibatch Loss= 0.004221, Training Accuracy= 1.00000\n",
      "Iter 692000, Minibatch Loss= 0.009712, Training Accuracy= 1.00000\n",
      "Iter 693000, Minibatch Loss= 0.012653, Training Accuracy= 1.00000\n",
      "Iter 694000, Minibatch Loss= 0.001818, Training Accuracy= 1.00000\n",
      "Iter 695000, Minibatch Loss= 0.006362, Training Accuracy= 1.00000\n",
      "Iter 696000, Minibatch Loss= 0.001866, Training Accuracy= 1.00000\n",
      "Iter 697000, Minibatch Loss= 0.036382, Training Accuracy= 0.99000\n",
      "Iter 698000, Minibatch Loss= 0.003268, Training Accuracy= 1.00000\n",
      "Iter 699000, Minibatch Loss= 0.023159, Training Accuracy= 0.99000\n",
      "Iter 700000, Minibatch Loss= 0.007419, Training Accuracy= 1.00000\n",
      "Iter 701000, Minibatch Loss= 0.003153, Training Accuracy= 1.00000\n",
      "Iter 702000, Minibatch Loss= 0.010891, Training Accuracy= 1.00000\n",
      "Iter 703000, Minibatch Loss= 0.030886, Training Accuracy= 0.99000\n",
      "Iter 704000, Minibatch Loss= 0.015897, Training Accuracy= 0.99000\n",
      "Iter 705000, Minibatch Loss= 0.007399, Training Accuracy= 1.00000\n",
      "Iter 706000, Minibatch Loss= 0.011063, Training Accuracy= 1.00000\n",
      "Iter 707000, Minibatch Loss= 0.010401, Training Accuracy= 0.99000\n",
      "Iter 708000, Minibatch Loss= 0.002356, Training Accuracy= 1.00000\n",
      "Iter 709000, Minibatch Loss= 0.002913, Training Accuracy= 1.00000\n",
      "Iter 710000, Minibatch Loss= 0.004688, Training Accuracy= 1.00000\n",
      "Iter 711000, Minibatch Loss= 0.004984, Training Accuracy= 1.00000\n",
      "Iter 712000, Minibatch Loss= 0.001402, Training Accuracy= 1.00000\n",
      "Iter 713000, Minibatch Loss= 0.012362, Training Accuracy= 0.99000\n",
      "Iter 714000, Minibatch Loss= 0.004941, Training Accuracy= 1.00000\n",
      "Iter 715000, Minibatch Loss= 0.005915, Training Accuracy= 1.00000\n",
      "Iter 716000, Minibatch Loss= 0.006639, Training Accuracy= 1.00000\n",
      "Iter 717000, Minibatch Loss= 0.016466, Training Accuracy= 0.99000\n",
      "Iter 718000, Minibatch Loss= 0.016633, Training Accuracy= 1.00000\n",
      "Iter 719000, Minibatch Loss= 0.001722, Training Accuracy= 1.00000\n",
      "Iter 720000, Minibatch Loss= 0.008319, Training Accuracy= 1.00000\n",
      "Iter 721000, Minibatch Loss= 0.002452, Training Accuracy= 1.00000\n",
      "Iter 722000, Minibatch Loss= 0.001779, Training Accuracy= 1.00000\n",
      "Iter 723000, Minibatch Loss= 0.009462, Training Accuracy= 1.00000\n",
      "Iter 724000, Minibatch Loss= 0.010083, Training Accuracy= 1.00000\n",
      "Iter 725000, Minibatch Loss= 0.005474, Training Accuracy= 1.00000\n",
      "Iter 726000, Minibatch Loss= 0.027937, Training Accuracy= 0.99000\n",
      "Iter 727000, Minibatch Loss= 0.010586, Training Accuracy= 1.00000\n",
      "Iter 728000, Minibatch Loss= 0.005259, Training Accuracy= 1.00000\n",
      "Iter 729000, Minibatch Loss= 0.005107, Training Accuracy= 1.00000\n",
      "Iter 730000, Minibatch Loss= 0.005940, Training Accuracy= 1.00000\n",
      "Iter 731000, Minibatch Loss= 0.002833, Training Accuracy= 1.00000\n",
      "Iter 732000, Minibatch Loss= 0.011019, Training Accuracy= 1.00000\n",
      "Iter 733000, Minibatch Loss= 0.003791, Training Accuracy= 1.00000\n",
      "Iter 734000, Minibatch Loss= 0.045975, Training Accuracy= 0.99000\n",
      "Iter 735000, Minibatch Loss= 0.005370, Training Accuracy= 1.00000\n",
      "Iter 736000, Minibatch Loss= 0.001946, Training Accuracy= 1.00000\n",
      "Iter 737000, Minibatch Loss= 0.005193, Training Accuracy= 1.00000\n",
      "Iter 738000, Minibatch Loss= 0.001273, Training Accuracy= 1.00000\n",
      "Iter 739000, Minibatch Loss= 0.003959, Training Accuracy= 1.00000\n",
      "Iter 740000, Minibatch Loss= 0.004090, Training Accuracy= 1.00000\n",
      "Iter 741000, Minibatch Loss= 0.005832, Training Accuracy= 1.00000\n",
      "Iter 742000, Minibatch Loss= 0.004788, Training Accuracy= 1.00000\n",
      "Iter 743000, Minibatch Loss= 0.007437, Training Accuracy= 1.00000\n",
      "Iter 744000, Minibatch Loss= 0.011361, Training Accuracy= 1.00000\n",
      "Iter 745000, Minibatch Loss= 0.025695, Training Accuracy= 0.99000\n",
      "Iter 746000, Minibatch Loss= 0.004197, Training Accuracy= 1.00000\n",
      "Iter 747000, Minibatch Loss= 0.005221, Training Accuracy= 1.00000\n",
      "Iter 748000, Minibatch Loss= 0.015916, Training Accuracy= 0.99000\n",
      "Iter 749000, Minibatch Loss= 0.005621, Training Accuracy= 1.00000\n",
      "Iter 750000, Minibatch Loss= 0.018988, Training Accuracy= 0.99000\n",
      "Iter 751000, Minibatch Loss= 0.033202, Training Accuracy= 0.99000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 752000, Minibatch Loss= 0.010878, Training Accuracy= 1.00000\n",
      "Iter 753000, Minibatch Loss= 0.003545, Training Accuracy= 1.00000\n",
      "Iter 754000, Minibatch Loss= 0.004410, Training Accuracy= 1.00000\n",
      "Iter 755000, Minibatch Loss= 0.001456, Training Accuracy= 1.00000\n",
      "Iter 756000, Minibatch Loss= 0.001085, Training Accuracy= 1.00000\n",
      "Iter 757000, Minibatch Loss= 0.040608, Training Accuracy= 0.99000\n",
      "Iter 758000, Minibatch Loss= 0.004716, Training Accuracy= 1.00000\n",
      "Iter 759000, Minibatch Loss= 0.023485, Training Accuracy= 0.99000\n",
      "Iter 760000, Minibatch Loss= 0.005077, Training Accuracy= 1.00000\n",
      "Iter 761000, Minibatch Loss= 0.004971, Training Accuracy= 1.00000\n",
      "Iter 762000, Minibatch Loss= 0.022686, Training Accuracy= 0.99000\n",
      "Iter 763000, Minibatch Loss= 0.010778, Training Accuracy= 0.99000\n",
      "Iter 764000, Minibatch Loss= 0.003891, Training Accuracy= 1.00000\n",
      "Iter 765000, Minibatch Loss= 0.040289, Training Accuracy= 0.98000\n",
      "Iter 766000, Minibatch Loss= 0.005949, Training Accuracy= 1.00000\n",
      "Iter 767000, Minibatch Loss= 0.001302, Training Accuracy= 1.00000\n",
      "Iter 768000, Minibatch Loss= 0.005120, Training Accuracy= 1.00000\n",
      "Iter 769000, Minibatch Loss= 0.017149, Training Accuracy= 0.99000\n",
      "Iter 770000, Minibatch Loss= 0.001784, Training Accuracy= 1.00000\n",
      "Iter 771000, Minibatch Loss= 0.000864, Training Accuracy= 1.00000\n",
      "Iter 772000, Minibatch Loss= 0.005084, Training Accuracy= 1.00000\n",
      "Iter 773000, Minibatch Loss= 0.005803, Training Accuracy= 1.00000\n",
      "Iter 774000, Minibatch Loss= 0.002592, Training Accuracy= 1.00000\n",
      "Iter 775000, Minibatch Loss= 0.012380, Training Accuracy= 0.99000\n",
      "Iter 776000, Minibatch Loss= 0.004018, Training Accuracy= 1.00000\n",
      "Iter 777000, Minibatch Loss= 0.001766, Training Accuracy= 1.00000\n",
      "Iter 778000, Minibatch Loss= 0.010375, Training Accuracy= 1.00000\n",
      "Iter 779000, Minibatch Loss= 0.014826, Training Accuracy= 0.99000\n",
      "Iter 780000, Minibatch Loss= 0.010833, Training Accuracy= 1.00000\n",
      "Iter 781000, Minibatch Loss= 0.004899, Training Accuracy= 1.00000\n",
      "Iter 782000, Minibatch Loss= 0.003298, Training Accuracy= 1.00000\n",
      "Iter 783000, Minibatch Loss= 0.001517, Training Accuracy= 1.00000\n",
      "Iter 784000, Minibatch Loss= 0.000725, Training Accuracy= 1.00000\n",
      "Iter 785000, Minibatch Loss= 0.004596, Training Accuracy= 1.00000\n",
      "Iter 786000, Minibatch Loss= 0.004299, Training Accuracy= 1.00000\n",
      "Iter 787000, Minibatch Loss= 0.003604, Training Accuracy= 1.00000\n",
      "Iter 788000, Minibatch Loss= 0.000302, Training Accuracy= 1.00000\n",
      "Iter 789000, Minibatch Loss= 0.002587, Training Accuracy= 1.00000\n",
      "Iter 790000, Minibatch Loss= 0.001340, Training Accuracy= 1.00000\n",
      "Iter 791000, Minibatch Loss= 0.000770, Training Accuracy= 1.00000\n",
      "Iter 792000, Minibatch Loss= 0.026093, Training Accuracy= 0.99000\n",
      "Iter 793000, Minibatch Loss= 0.003221, Training Accuracy= 1.00000\n",
      "Iter 794000, Minibatch Loss= 0.001662, Training Accuracy= 1.00000\n",
      "Iter 795000, Minibatch Loss= 0.008882, Training Accuracy= 1.00000\n",
      "Iter 796000, Minibatch Loss= 0.001385, Training Accuracy= 1.00000\n",
      "Iter 797000, Minibatch Loss= 0.002617, Training Accuracy= 1.00000\n",
      "Iter 798000, Minibatch Loss= 0.007269, Training Accuracy= 1.00000\n",
      "Iter 799000, Minibatch Loss= 0.004982, Training Accuracy= 1.00000\n",
      "Iter 800000, Minibatch Loss= 0.001830, Training Accuracy= 1.00000\n",
      "Iter 801000, Minibatch Loss= 0.000280, Training Accuracy= 1.00000\n",
      "Iter 802000, Minibatch Loss= 0.032866, Training Accuracy= 0.99000\n",
      "Iter 803000, Minibatch Loss= 0.012508, Training Accuracy= 0.99000\n",
      "Iter 804000, Minibatch Loss= 0.006313, Training Accuracy= 1.00000\n",
      "Iter 805000, Minibatch Loss= 0.008698, Training Accuracy= 1.00000\n",
      "Iter 806000, Minibatch Loss= 0.010728, Training Accuracy= 1.00000\n",
      "Iter 807000, Minibatch Loss= 0.007556, Training Accuracy= 1.00000\n",
      "Iter 808000, Minibatch Loss= 0.009569, Training Accuracy= 0.99000\n",
      "Iter 809000, Minibatch Loss= 0.004468, Training Accuracy= 1.00000\n",
      "Iter 810000, Minibatch Loss= 0.000983, Training Accuracy= 1.00000\n",
      "Iter 811000, Minibatch Loss= 0.006990, Training Accuracy= 1.00000\n",
      "Iter 812000, Minibatch Loss= 0.001418, Training Accuracy= 1.00000\n",
      "Iter 813000, Minibatch Loss= 0.001492, Training Accuracy= 1.00000\n",
      "Iter 814000, Minibatch Loss= 0.007315, Training Accuracy= 1.00000\n",
      "Iter 815000, Minibatch Loss= 0.011894, Training Accuracy= 1.00000\n",
      "Iter 816000, Minibatch Loss= 0.001470, Training Accuracy= 1.00000\n",
      "Iter 817000, Minibatch Loss= 0.006336, Training Accuracy= 1.00000\n",
      "Iter 818000, Minibatch Loss= 0.002179, Training Accuracy= 1.00000\n",
      "Iter 819000, Minibatch Loss= 0.005556, Training Accuracy= 1.00000\n",
      "Iter 820000, Minibatch Loss= 0.002164, Training Accuracy= 1.00000\n",
      "Iter 821000, Minibatch Loss= 0.006200, Training Accuracy= 1.00000\n",
      "Iter 822000, Minibatch Loss= 0.018039, Training Accuracy= 0.99000\n",
      "Iter 823000, Minibatch Loss= 0.029314, Training Accuracy= 0.99000\n",
      "Iter 824000, Minibatch Loss= 0.027110, Training Accuracy= 0.99000\n",
      "Iter 825000, Minibatch Loss= 0.006202, Training Accuracy= 1.00000\n",
      "Iter 826000, Minibatch Loss= 0.012734, Training Accuracy= 1.00000\n",
      "Iter 827000, Minibatch Loss= 0.072332, Training Accuracy= 0.99000\n",
      "Iter 828000, Minibatch Loss= 0.001961, Training Accuracy= 1.00000\n",
      "Iter 829000, Minibatch Loss= 0.065103, Training Accuracy= 0.98000\n",
      "Iter 830000, Minibatch Loss= 0.001941, Training Accuracy= 1.00000\n",
      "Iter 831000, Minibatch Loss= 0.001111, Training Accuracy= 1.00000\n",
      "Iter 832000, Minibatch Loss= 0.009530, Training Accuracy= 1.00000\n",
      "Iter 833000, Minibatch Loss= 0.034988, Training Accuracy= 0.98000\n",
      "Iter 834000, Minibatch Loss= 0.017078, Training Accuracy= 0.99000\n",
      "Iter 835000, Minibatch Loss= 0.003090, Training Accuracy= 1.00000\n",
      "Iter 836000, Minibatch Loss= 0.007991, Training Accuracy= 1.00000\n",
      "Iter 837000, Minibatch Loss= 0.000425, Training Accuracy= 1.00000\n",
      "Iter 838000, Minibatch Loss= 0.000609, Training Accuracy= 1.00000\n",
      "Iter 839000, Minibatch Loss= 0.007578, Training Accuracy= 1.00000\n",
      "Iter 840000, Minibatch Loss= 0.009046, Training Accuracy= 1.00000\n",
      "Iter 841000, Minibatch Loss= 0.001249, Training Accuracy= 1.00000\n",
      "Iter 842000, Minibatch Loss= 0.000988, Training Accuracy= 1.00000\n",
      "Iter 843000, Minibatch Loss= 0.002889, Training Accuracy= 1.00000\n",
      "Iter 844000, Minibatch Loss= 0.027661, Training Accuracy= 0.99000\n",
      "Iter 845000, Minibatch Loss= 0.002010, Training Accuracy= 1.00000\n",
      "Iter 846000, Minibatch Loss= 0.004200, Training Accuracy= 1.00000\n",
      "Iter 847000, Minibatch Loss= 0.001283, Training Accuracy= 1.00000\n",
      "Iter 848000, Minibatch Loss= 0.010319, Training Accuracy= 1.00000\n",
      "Iter 849000, Minibatch Loss= 0.008271, Training Accuracy= 1.00000\n",
      "Iter 850000, Minibatch Loss= 0.029429, Training Accuracy= 0.98000\n",
      "Iter 851000, Minibatch Loss= 0.009298, Training Accuracy= 1.00000\n",
      "Iter 852000, Minibatch Loss= 0.005562, Training Accuracy= 1.00000\n",
      "Iter 853000, Minibatch Loss= 0.011976, Training Accuracy= 0.99000\n",
      "Iter 854000, Minibatch Loss= 0.015058, Training Accuracy= 1.00000\n",
      "Iter 855000, Minibatch Loss= 0.002328, Training Accuracy= 1.00000\n",
      "Iter 856000, Minibatch Loss= 0.004688, Training Accuracy= 1.00000\n",
      "Iter 857000, Minibatch Loss= 0.029345, Training Accuracy= 0.98000\n",
      "Iter 858000, Minibatch Loss= 0.003528, Training Accuracy= 1.00000\n",
      "Iter 859000, Minibatch Loss= 0.000358, Training Accuracy= 1.00000\n",
      "Iter 860000, Minibatch Loss= 0.000370, Training Accuracy= 1.00000\n",
      "Iter 861000, Minibatch Loss= 0.001921, Training Accuracy= 1.00000\n",
      "Iter 862000, Minibatch Loss= 0.001066, Training Accuracy= 1.00000\n",
      "Iter 863000, Minibatch Loss= 0.004958, Training Accuracy= 1.00000\n",
      "Iter 864000, Minibatch Loss= 0.006214, Training Accuracy= 1.00000\n",
      "Iter 865000, Minibatch Loss= 0.007156, Training Accuracy= 1.00000\n",
      "Iter 866000, Minibatch Loss= 0.002574, Training Accuracy= 1.00000\n",
      "Iter 867000, Minibatch Loss= 0.001996, Training Accuracy= 1.00000\n",
      "Iter 868000, Minibatch Loss= 0.007775, Training Accuracy= 1.00000\n",
      "Iter 869000, Minibatch Loss= 0.000372, Training Accuracy= 1.00000\n",
      "Iter 870000, Minibatch Loss= 0.002647, Training Accuracy= 1.00000\n",
      "Iter 871000, Minibatch Loss= 0.002889, Training Accuracy= 1.00000\n",
      "Iter 872000, Minibatch Loss= 0.012410, Training Accuracy= 1.00000\n",
      "Iter 873000, Minibatch Loss= 0.011479, Training Accuracy= 0.99000\n",
      "Iter 874000, Minibatch Loss= 0.008205, Training Accuracy= 0.99000\n",
      "Iter 875000, Minibatch Loss= 0.005536, Training Accuracy= 1.00000\n",
      "Iter 876000, Minibatch Loss= 0.016580, Training Accuracy= 0.99000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 877000, Minibatch Loss= 0.001837, Training Accuracy= 1.00000\n",
      "Iter 878000, Minibatch Loss= 0.000654, Training Accuracy= 1.00000\n",
      "Iter 879000, Minibatch Loss= 0.006143, Training Accuracy= 1.00000\n",
      "Iter 880000, Minibatch Loss= 0.005184, Training Accuracy= 1.00000\n",
      "Iter 881000, Minibatch Loss= 0.004813, Training Accuracy= 1.00000\n",
      "Iter 882000, Minibatch Loss= 0.041236, Training Accuracy= 0.98000\n",
      "Iter 883000, Minibatch Loss= 0.001114, Training Accuracy= 1.00000\n",
      "Iter 884000, Minibatch Loss= 0.008984, Training Accuracy= 0.99000\n",
      "Iter 885000, Minibatch Loss= 0.008985, Training Accuracy= 1.00000\n",
      "Iter 886000, Minibatch Loss= 0.007883, Training Accuracy= 1.00000\n",
      "Iter 887000, Minibatch Loss= 0.007269, Training Accuracy= 1.00000\n",
      "Iter 888000, Minibatch Loss= 0.013608, Training Accuracy= 1.00000\n",
      "Iter 889000, Minibatch Loss= 0.001990, Training Accuracy= 1.00000\n",
      "Iter 890000, Minibatch Loss= 0.000756, Training Accuracy= 1.00000\n",
      "Iter 891000, Minibatch Loss= 0.015726, Training Accuracy= 0.99000\n",
      "Iter 892000, Minibatch Loss= 0.011876, Training Accuracy= 0.99000\n",
      "Iter 893000, Minibatch Loss= 0.000383, Training Accuracy= 1.00000\n",
      "Iter 894000, Minibatch Loss= 0.003676, Training Accuracy= 1.00000\n",
      "Iter 895000, Minibatch Loss= 0.008507, Training Accuracy= 1.00000\n",
      "Iter 896000, Minibatch Loss= 0.005561, Training Accuracy= 1.00000\n",
      "Iter 897000, Minibatch Loss= 0.003765, Training Accuracy= 1.00000\n",
      "Iter 898000, Minibatch Loss= 0.021060, Training Accuracy= 0.99000\n",
      "Iter 899000, Minibatch Loss= 0.006087, Training Accuracy= 1.00000\n",
      "Iter 900000, Minibatch Loss= 0.003514, Training Accuracy= 1.00000\n",
      "Iter 901000, Minibatch Loss= 0.002705, Training Accuracy= 1.00000\n",
      "Iter 902000, Minibatch Loss= 0.001627, Training Accuracy= 1.00000\n",
      "Iter 903000, Minibatch Loss= 0.008822, Training Accuracy= 1.00000\n",
      "Iter 904000, Minibatch Loss= 0.000848, Training Accuracy= 1.00000\n",
      "Iter 905000, Minibatch Loss= 0.000760, Training Accuracy= 1.00000\n",
      "Iter 906000, Minibatch Loss= 0.003026, Training Accuracy= 1.00000\n",
      "Iter 907000, Minibatch Loss= 0.010819, Training Accuracy= 0.99000\n",
      "Iter 908000, Minibatch Loss= 0.009338, Training Accuracy= 1.00000\n",
      "Iter 909000, Minibatch Loss= 0.003822, Training Accuracy= 1.00000\n",
      "Iter 910000, Minibatch Loss= 0.003854, Training Accuracy= 1.00000\n",
      "Iter 911000, Minibatch Loss= 0.001719, Training Accuracy= 1.00000\n",
      "Iter 912000, Minibatch Loss= 0.002945, Training Accuracy= 1.00000\n",
      "Iter 913000, Minibatch Loss= 0.002125, Training Accuracy= 1.00000\n",
      "Iter 914000, Minibatch Loss= 0.001862, Training Accuracy= 1.00000\n",
      "Iter 915000, Minibatch Loss= 0.000562, Training Accuracy= 1.00000\n",
      "Iter 916000, Minibatch Loss= 0.007474, Training Accuracy= 1.00000\n",
      "Iter 917000, Minibatch Loss= 0.017030, Training Accuracy= 0.99000\n",
      "Iter 918000, Minibatch Loss= 0.002187, Training Accuracy= 1.00000\n",
      "Iter 919000, Minibatch Loss= 0.004451, Training Accuracy= 1.00000\n",
      "Iter 920000, Minibatch Loss= 0.010905, Training Accuracy= 0.99000\n",
      "Iter 921000, Minibatch Loss= 0.015456, Training Accuracy= 0.99000\n",
      "Iter 922000, Minibatch Loss= 0.000750, Training Accuracy= 1.00000\n",
      "Iter 923000, Minibatch Loss= 0.025610, Training Accuracy= 0.99000\n",
      "Iter 924000, Minibatch Loss= 0.004249, Training Accuracy= 1.00000\n",
      "Iter 925000, Minibatch Loss= 0.009581, Training Accuracy= 0.99000\n",
      "Iter 926000, Minibatch Loss= 0.002341, Training Accuracy= 1.00000\n",
      "Iter 927000, Minibatch Loss= 0.012835, Training Accuracy= 1.00000\n",
      "Iter 928000, Minibatch Loss= 0.004922, Training Accuracy= 1.00000\n",
      "Iter 929000, Minibatch Loss= 0.000338, Training Accuracy= 1.00000\n",
      "Iter 930000, Minibatch Loss= 0.005644, Training Accuracy= 1.00000\n",
      "Iter 931000, Minibatch Loss= 0.001456, Training Accuracy= 1.00000\n",
      "Iter 932000, Minibatch Loss= 0.013098, Training Accuracy= 0.99000\n",
      "Iter 933000, Minibatch Loss= 0.000786, Training Accuracy= 1.00000\n",
      "Iter 934000, Minibatch Loss= 0.002875, Training Accuracy= 1.00000\n",
      "Iter 935000, Minibatch Loss= 0.002283, Training Accuracy= 1.00000\n",
      "Iter 936000, Minibatch Loss= 0.000810, Training Accuracy= 1.00000\n",
      "Iter 937000, Minibatch Loss= 0.004489, Training Accuracy= 1.00000\n",
      "Iter 938000, Minibatch Loss= 0.002843, Training Accuracy= 1.00000\n",
      "Iter 939000, Minibatch Loss= 0.014773, Training Accuracy= 0.99000\n",
      "Iter 940000, Minibatch Loss= 0.017082, Training Accuracy= 0.99000\n",
      "Iter 941000, Minibatch Loss= 0.004159, Training Accuracy= 1.00000\n",
      "Iter 942000, Minibatch Loss= 0.008160, Training Accuracy= 1.00000\n",
      "Iter 943000, Minibatch Loss= 0.011058, Training Accuracy= 0.99000\n",
      "Iter 944000, Minibatch Loss= 0.003156, Training Accuracy= 1.00000\n",
      "Iter 945000, Minibatch Loss= 0.003253, Training Accuracy= 1.00000\n",
      "Iter 946000, Minibatch Loss= 0.001328, Training Accuracy= 1.00000\n",
      "Iter 947000, Minibatch Loss= 0.002531, Training Accuracy= 1.00000\n",
      "Iter 948000, Minibatch Loss= 0.011226, Training Accuracy= 0.99000\n",
      "Iter 949000, Minibatch Loss= 0.002215, Training Accuracy= 1.00000\n",
      "Iter 950000, Minibatch Loss= 0.001336, Training Accuracy= 1.00000\n",
      "Iter 951000, Minibatch Loss= 0.030691, Training Accuracy= 0.99000\n",
      "Iter 952000, Minibatch Loss= 0.001709, Training Accuracy= 1.00000\n",
      "Iter 953000, Minibatch Loss= 0.009817, Training Accuracy= 1.00000\n",
      "Iter 954000, Minibatch Loss= 0.002211, Training Accuracy= 1.00000\n",
      "Iter 955000, Minibatch Loss= 0.002164, Training Accuracy= 1.00000\n",
      "Iter 956000, Minibatch Loss= 0.000951, Training Accuracy= 1.00000\n",
      "Iter 957000, Minibatch Loss= 0.004130, Training Accuracy= 1.00000\n",
      "Iter 958000, Minibatch Loss= 0.001074, Training Accuracy= 1.00000\n",
      "Iter 959000, Minibatch Loss= 0.003186, Training Accuracy= 1.00000\n",
      "Iter 960000, Minibatch Loss= 0.006390, Training Accuracy= 1.00000\n",
      "Iter 961000, Minibatch Loss= 0.006270, Training Accuracy= 1.00000\n",
      "Iter 962000, Minibatch Loss= 0.003197, Training Accuracy= 1.00000\n",
      "Iter 963000, Minibatch Loss= 0.003198, Training Accuracy= 1.00000\n",
      "Iter 964000, Minibatch Loss= 0.000923, Training Accuracy= 1.00000\n",
      "Iter 965000, Minibatch Loss= 0.001739, Training Accuracy= 1.00000\n",
      "Iter 966000, Minibatch Loss= 0.014140, Training Accuracy= 0.99000\n",
      "Iter 967000, Minibatch Loss= 0.017170, Training Accuracy= 1.00000\n",
      "Iter 968000, Minibatch Loss= 0.000655, Training Accuracy= 1.00000\n",
      "Iter 969000, Minibatch Loss= 0.002507, Training Accuracy= 1.00000\n",
      "Iter 970000, Minibatch Loss= 0.002419, Training Accuracy= 1.00000\n",
      "Iter 971000, Minibatch Loss= 0.006231, Training Accuracy= 1.00000\n",
      "Iter 972000, Minibatch Loss= 0.001999, Training Accuracy= 1.00000\n",
      "Iter 973000, Minibatch Loss= 0.002219, Training Accuracy= 1.00000\n",
      "Iter 974000, Minibatch Loss= 0.000287, Training Accuracy= 1.00000\n",
      "Iter 975000, Minibatch Loss= 0.001112, Training Accuracy= 1.00000\n",
      "Iter 976000, Minibatch Loss= 0.005089, Training Accuracy= 1.00000\n",
      "Iter 977000, Minibatch Loss= 0.003046, Training Accuracy= 1.00000\n",
      "Iter 978000, Minibatch Loss= 0.000762, Training Accuracy= 1.00000\n",
      "Iter 979000, Minibatch Loss= 0.017055, Training Accuracy= 0.99000\n",
      "Iter 980000, Minibatch Loss= 0.005649, Training Accuracy= 1.00000\n",
      "Iter 981000, Minibatch Loss= 0.000580, Training Accuracy= 1.00000\n",
      "Iter 982000, Minibatch Loss= 0.006812, Training Accuracy= 1.00000\n",
      "Iter 983000, Minibatch Loss= 0.009103, Training Accuracy= 1.00000\n",
      "Iter 984000, Minibatch Loss= 0.003520, Training Accuracy= 1.00000\n",
      "Iter 985000, Minibatch Loss= 0.002988, Training Accuracy= 1.00000\n",
      "Iter 986000, Minibatch Loss= 0.028958, Training Accuracy= 0.99000\n",
      "Iter 987000, Minibatch Loss= 0.003560, Training Accuracy= 1.00000\n",
      "Iter 988000, Minibatch Loss= 0.004464, Training Accuracy= 1.00000\n",
      "Iter 989000, Minibatch Loss= 0.015502, Training Accuracy= 0.99000\n",
      "Iter 990000, Minibatch Loss= 0.005637, Training Accuracy= 1.00000\n",
      "Iter 991000, Minibatch Loss= 0.007827, Training Accuracy= 1.00000\n",
      "Iter 992000, Minibatch Loss= 0.009811, Training Accuracy= 0.99000\n",
      "Iter 993000, Minibatch Loss= 0.003155, Training Accuracy= 1.00000\n",
      "Iter 994000, Minibatch Loss= 0.003872, Training Accuracy= 1.00000\n",
      "Iter 995000, Minibatch Loss= 0.000545, Training Accuracy= 1.00000\n",
      "Iter 996000, Minibatch Loss= 0.002082, Training Accuracy= 1.00000\n",
      "Iter 997000, Minibatch Loss= 0.001523, Training Accuracy= 1.00000\n",
      "Iter 998000, Minibatch Loss= 0.009989, Training Accuracy= 1.00000\n",
      "Iter 999000, Minibatch Loss= 0.008338, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.984375)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "training_iters = 1000000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        # We will read a batch of 100 images [100 x 784] as batch_x\n",
    "        # batch_y is a matrix of [100x10]\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # We consider each row of the image as one sequence\n",
    "        # Reshape data to get 28 seq of 28 elements, so that, batxh_x is [100x28x28]\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    \n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Created by <a href=\"https://br.linkedin.com/in/walter-gomes-de-amorim-junior-624726121\">Walter Gomes de Amorim Junior</a> ,  <a href = \"https://linkedin.com/in/saeedaghabozorgi\"> Saeed Aghabozorgi </a></h4>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
