{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na1: (1, 2) ,na2: (2,) ,na3: (1, 1, 2)\n",
      "na1: <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "na2: <class 'tensorflow.python.framework.ops.Tensor'> \n",
      "na3: <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "na1 = tf.constant([[1.,5.]])\n",
    "na2 = tf.constant([1.,5.])\n",
    "na3 = tf.constant([[[1.,5.]]])\n",
    "print \"na1:\",na1.shape,\",na2:\",na2.shape,\",na3:\",na3.shape\n",
    "print \"na1:\",type(na1),\"\\nna2:\",type(na2),\"\\nna3:\",type(na3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_4:0\", shape=(1, 1), dtype=float32)\n",
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# 创建另外一个常量 op, 产生一个 2x1 矩阵.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print product\n",
    "    print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.constant([[1.,2.],\n",
    "               [3.,4.]])\n",
    "y=tf.reduce_mean(x)\n",
    "z=tf.reduce_mean(x,0)\n",
    "u=tf.reduce_mean(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= 2.5\n",
      "z= [ 2.  3.]\n",
      "u= [ 1.5  3.5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    result = session.run(y)\n",
    "    print \"y= %s\" % result\n",
    "    result = session.run(z)\n",
    "    print \"z= %s\" % result\n",
    "    result = session.run(u)\n",
    "    print \"u= %s\"%result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2= [[ 2.  3.  4.]\n",
      " [ 1.  2.  5.]]\n",
      "z2= [[ 3.  2.  5.]\n",
      " [ 2.  1.  6.]]\n",
      "t= [[2, 3, 4], [1, 2, 5], 1, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "#此处验证矩阵加法，如何让矩阵加一个向量。\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x = tf.Variable(tf.zeros([2,3],tf.float32))\n",
    "b = tf.Variable(tf.zeros([3],tf.float32))\n",
    "y = tf.assign(x,[[2,3,4],[1,2,5]])\n",
    "b2 = tf.assign(b,[1,-1,1])                \n",
    "z = y+b2  #此处的加法，将b2【3】的向量分别加到y【2x3】矩阵的每一行上\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y2= sess.run(y)\n",
    "    z2 = sess.run(z)\n",
    "    print \"y2=\",y2\n",
    "    print \"z2=\",z2\n",
    "r=[[2,3,4],[1,2,5]]\n",
    "s=[1,-1,1]\n",
    "t = r+s #此处的加法，是将向量s【3】追加到矩阵r【2x3】的最后，形成一个【3x3】矩阵。\n",
    "print \"t=\",t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n",
      "yr= [[[  1.   2.   3.]\n",
      "  [  4.   5.   6.]]\n",
      "\n",
      " [[  7.   8.   9.]\n",
      "  [ 10.  11.  12.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "x = tf.Variable(tf.zeros([2,6],tf.float32))\n",
    "\n",
    "z= tf.assign(x,[[1,2,3,4,5,6],[7,8,9,10,11,12]])\n",
    "y = tf.reshape(z,[-1,2,3])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print \"x=\",x.eval()\n",
    "    \n",
    "    yr = sess.run(y)\n",
    "    print \"yr=\",yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    a\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(list('abca'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.get_dummies(s)\n",
    "#type(t)\n",
    "r = t.values\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Const_14:0' shape=() dtype=float32>, <tf.Tensor 'Const_15:0' shape=() dtype=float32>)\n",
      "[3.0, 4.0]\n",
      "('sess.run(node3):', 7.0)\n",
      "7.5\n",
      "[ 3.  7.]\n",
      "22.5\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)\n",
    "sess = tf.Session()\n",
    "result = sess.run([node1, node2])\n",
    "print(result)\n",
    "node3 = tf.add(node1, node2)\n",
    "print(\"sess.run(node3):\", sess.run(node3))\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "print(sess.run(adder_node, {a:3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))\n",
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, {a: 3, b: 4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64200008  0.          0.30000001  0.60000002]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "linear_model = W * x + b\n",
    "linear_model\n",
    "print(sess.run(linear_model,{x:[3.14,1,2,3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "zy= [3 3]\n"
     ]
    }
   ],
   "source": [
    "zx = tf.constant([[1,1,1],[1,1,1]])\n",
    "print zx.shape\n",
    "zy = tf.reduce_sum(zx,1)\n",
    "zr = sess.run(zy)\n",
    "print \"zy=\",zr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9999969, 0.99999082]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder (tf.float32)\n",
    "W = tf.Variable(.3 , dtype=tf.float32)\n",
    "b = tf.Variable(-.3,dtype=tf.float32)\n",
    "vinit = tf.global_variables_initializer()\n",
    "lm = W*x+b\n",
    "sq = tf.square(lm - y)\n",
    "loss = tf.reduce_sum(sq)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(vinit)\n",
    "for i in range(1000):\n",
    "    sess.run(train,{x:[1,2,3,4],y:[0,-1,-2,-3]})\n",
    "print(sess.run([W, b]))\n",
    "#print W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zr= [ 0.  0.  0.]\n",
      "zr2= [[ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "zz = tf.zeros([3])\n",
    "zz2=tf.zeros([1,3])\n",
    "zr = sess.run(zz)\n",
    "zr2=sess.run(zz2)\n",
    "print \"zr=\",zr\n",
    "print \"zr2=\",zr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30948308 -0.52688724 -0.16754265]\n",
      " [-0.40847349 -1.21165311  0.77639049]\n",
      " [ 1.18179858 -0.36526814 -1.741045  ]]\n",
      "[[[[-0.07763758 -0.19292486 -0.01697135  0.04260815 -0.10561567  0.04235503\n",
      "    -0.10373684  0.10107751  0.09830898  0.06095357  0.00485296  0.07568271\n",
      "     0.00724091 -0.07585794 -0.04595007  0.02950489 -0.02763073 -0.01654856\n",
      "     0.09304058 -0.03180665  0.00439753 -0.07705075  0.06384693  0.11988862\n",
      "     0.00763007  0.09971558 -0.1502797  -0.07892548 -0.04794798  0.05814451\n",
      "     0.08477338 -0.024729  ]]\n",
      "\n",
      "  [[-0.07192839  0.00455693  0.03780096 -0.04098595  0.19249912 -0.10610469\n",
      "     0.14180768  0.08550525 -0.06988584 -0.06329756  0.11106122  0.05853065\n",
      "     0.04438072 -0.03845915 -0.02621862  0.09460219 -0.10954858  0.01011253\n",
      "     0.03287388 -0.00164157  0.06429213  0.05903031  0.10408294  0.04855515\n",
      "     0.06105424 -0.03100383  0.01104861 -0.1872834  -0.07646006  0.03236635\n",
      "    -0.08718151 -0.00681558]]\n",
      "\n",
      "  [[ 0.13880114  0.10111462 -0.18542321  0.15676074  0.07650252  0.16645737\n",
      "    -0.10863024  0.13958865  0.05351215  0.14023919 -0.14024696 -0.03448756\n",
      "    -0.18353902 -0.00760565  0.0820077   0.04051175 -0.07960648  0.11240627\n",
      "     0.05720592 -0.02145292  0.0411946   0.03151721  0.03488201 -0.07302408\n",
      "     0.01256787 -0.03953036 -0.01789103 -0.02158674 -0.04147702  0.04320839\n",
      "     0.01367236  0.00819874]]\n",
      "\n",
      "  [[ 0.02141863 -0.00508648  0.03475652 -0.06554486  0.00566797  0.07618154\n",
      "    -0.13745503 -0.05292772  0.10525125 -0.06622452  0.04466194 -0.12057926\n",
      "    -0.04925177  0.01963991 -0.13022918  0.03740383  0.09964639  0.05374154\n",
      "    -0.06685919  0.04419374  0.12407891  0.10042649  0.09857827 -0.01878756\n",
      "     0.00497871  0.1320768   0.01331296 -0.04420127  0.11993145  0.08556566\n",
      "    -0.02488417  0.01545364]]\n",
      "\n",
      "  [[ 0.18202892 -0.1505103  -0.10673292 -0.01827099  0.01363568  0.09275266\n",
      "     0.07870361 -0.11841624  0.0133908   0.00934115  0.05984946  0.1113716\n",
      "    -0.15061215 -0.04008856  0.15044712  0.15764578  0.06528491  0.12714843\n",
      "    -0.07053917  0.02985659 -0.0023529   0.1115968   0.00935191 -0.02486229\n",
      "    -0.13541074 -0.01270778  0.03183877  0.02975049  0.02109181  0.03187285\n",
      "    -0.01314531  0.10669412]]]\n",
      "\n",
      "\n",
      " [[[ 0.03549067 -0.08063774 -0.00427757 -0.11576926 -0.1560128   0.07275348\n",
      "    -0.10611953  0.08855436 -0.05791441  0.09321319 -0.02567601  0.18939757\n",
      "     0.01006834  0.05382955  0.02197543 -0.01481715  0.06992482  0.13785198\n",
      "     0.04178061  0.01447508  0.10186204  0.10847987  0.1496533  -0.11749469\n",
      "    -0.03486502  0.10853042 -0.03348329 -0.06833549 -0.00451759 -0.02576606\n",
      "    -0.02848749 -0.06316912]]\n",
      "\n",
      "  [[-0.13999574  0.00256736  0.01769763 -0.13324867  0.06207827 -0.03229835\n",
      "    -0.08158302  0.02846799 -0.05539566  0.01068097 -0.07134006 -0.10748535\n",
      "    -0.09450128 -0.12865381 -0.14039712 -0.12771992 -0.00456457  0.01969041\n",
      "     0.12146473 -0.17267595 -0.05836187 -0.12303536  0.032063   -0.02824729\n",
      "    -0.12950672  0.02875458  0.07494629  0.00678834 -0.07935903  0.14967026\n",
      "    -0.03413002 -0.13032292]]\n",
      "\n",
      "  [[ 0.0213562   0.04162413 -0.07481716 -0.14424877 -0.12367393  0.12207586\n",
      "    -0.09987996  0.00752637 -0.1356356   0.00646305 -0.01374354 -0.00152947\n",
      "     0.00381911  0.03612868  0.12748489  0.09721317 -0.00459686  0.01879183\n",
      "    -0.11743367  0.01942774  0.01492712 -0.0791836   0.09877822  0.07101533\n",
      "     0.06674015  0.05046939  0.09867591 -0.03907074 -0.04836427 -0.02271937\n",
      "    -0.11389404  0.12756874]]\n",
      "\n",
      "  [[-0.01286062  0.1156543  -0.01604871 -0.08159515 -0.02163105  0.0188878\n",
      "    -0.09908681 -0.04533409  0.0124475  -0.03260963  0.1149288  -0.01940669\n",
      "     0.10650902  0.0068424   0.03570785 -0.08107112  0.15632668  0.08555037\n",
      "     0.0683146   0.04428566  0.15376022  0.01499313 -0.0764054   0.00078931\n",
      "     0.11416034 -0.07769649 -0.12916037 -0.1999402  -0.06245086  0.00283717\n",
      "     0.02631508  0.01895192]]\n",
      "\n",
      "  [[-0.03213404 -0.1275838   0.01685674 -0.09104854  0.02818116  0.01307192\n",
      "     0.04348949 -0.0179319   0.02063992 -0.0090566   0.09124477  0.00866916\n",
      "     0.08962902  0.17069851 -0.02886226 -0.0857615   0.12618838 -0.02943449\n",
      "    -0.00108751  0.10848854 -0.14108936 -0.17351085 -0.06927511  0.0501084\n",
      "     0.12587057 -0.06762156 -0.05930812 -0.06144568 -0.01313119 -0.03920771\n",
      "     0.16057342 -0.08067685]]]\n",
      "\n",
      "\n",
      " [[[ 0.04158703  0.07751927 -0.19075459 -0.03168714  0.01517894  0.0363177\n",
      "     0.02383765  0.15848812 -0.06198461  0.07630003  0.15304227 -0.1452499\n",
      "    -0.12658547 -0.09433831 -0.09755363 -0.01031711 -0.06822167  0.05829256\n",
      "     0.01840157  0.03045321  0.06907159 -0.14220062 -0.13209367  0.06901889\n",
      "     0.00660341 -0.07199451 -0.0025545   0.04151268  0.08372446  0.12921248\n",
      "    -0.10709532 -0.0249554 ]]\n",
      "\n",
      "  [[-0.00175409 -0.06796124  0.06073247  0.00246306 -0.11682682  0.06708533\n",
      "     0.19394539  0.08213495 -0.02280138  0.06086404 -0.06081839  0.06155535\n",
      "    -0.03486679 -0.13720174 -0.09670519 -0.09319802  0.06364349  0.00890657\n",
      "     0.0325545  -0.06345053  0.06301578  0.06102213 -0.1264326  -0.09087483\n",
      "    -0.15207341  0.06839642  0.16030991 -0.19131766  0.15115374 -0.12132501\n",
      "    -0.18716778  0.04789513]]\n",
      "\n",
      "  [[ 0.04460217 -0.09919881 -0.00236528  0.07988599  0.07519131 -0.06843033\n",
      "     0.03968795 -0.1028968  -0.19398326 -0.06992713 -0.0205221  -0.16062418\n",
      "     0.06132779 -0.00431496 -0.06236776 -0.06472185 -0.06752397  0.05555342\n",
      "     0.1691073  -0.06438904 -0.00960056  0.15050451 -0.14696176  0.10550344\n",
      "    -0.00777796 -0.08321016  0.0495801   0.11136089  0.00934555 -0.0532625\n",
      "    -0.07315471  0.17171942]]\n",
      "\n",
      "  [[-0.07149021  0.15038234 -0.11683881 -0.12666073  0.08367727 -0.01630424\n",
      "    -0.12007397 -0.12039411  0.075985    0.10964178  0.05834657  0.08509006\n",
      "     0.06036679  0.15975425 -0.12427931  0.12564453 -0.10698444 -0.01865732\n",
      "    -0.07325459  0.06404494 -0.12710133  0.09967455 -0.03736442 -0.13466409\n",
      "     0.03255121 -0.04305868  0.07842874 -0.00430545 -0.08189008  0.06365252\n",
      "     0.09407596  0.0099856 ]]\n",
      "\n",
      "  [[-0.07609279 -0.01877406 -0.15939321 -0.03593183  0.10087873  0.02902147\n",
      "     0.09104411 -0.00705661  0.11941852  0.06728833 -0.00793018 -0.06823471\n",
      "    -0.13587573 -0.13357186 -0.10826804  0.04767055  0.03754252 -0.05114178\n",
      "     0.01797394 -0.12956846  0.09277997  0.06318182  0.13604252  0.10424568\n",
      "    -0.06299594 -0.02064868 -0.02425539 -0.13149506 -0.08690926  0.01669169\n",
      "    -0.01836913 -0.16137101]]]\n",
      "\n",
      "\n",
      " [[[ 0.02782891 -0.09785879 -0.02506465 -0.09080291  0.16228463 -0.01130751\n",
      "     0.00618499  0.05626856 -0.07823338  0.15026203 -0.08194344 -0.10533017\n",
      "    -0.03980061 -0.13398266 -0.00600552  0.08872933 -0.03808346 -0.11412515\n",
      "    -0.04903895  0.15335241 -0.00928083  0.1052172   0.10133056  0.08214049\n",
      "    -0.08234145  0.01551098  0.17025103 -0.10429382  0.09440796 -0.04421845\n",
      "    -0.04275182 -0.05431074]]\n",
      "\n",
      "  [[ 0.04988366  0.01484061 -0.00499412  0.04271804  0.05503657  0.00410948\n",
      "     0.0255735   0.09897851  0.01869874 -0.11429156 -0.132852    0.12668942\n",
      "    -0.13027155 -0.03794665 -0.10272583 -0.12229464  0.12183622  0.14522207\n",
      "    -0.17281887 -0.00686997 -0.05418833 -0.11725998  0.00761174 -0.00486631\n",
      "    -0.03831866 -0.01474828  0.09704158 -0.01141669  0.05583795 -0.09966438\n",
      "     0.01289495 -0.02430641]]\n",
      "\n",
      "  [[-0.00638161 -0.18931183 -0.14217974 -0.01018536 -0.04845944 -0.11098655\n",
      "     0.14529136  0.08734038 -0.04619234 -0.0256773  -0.07419976 -0.05235586\n",
      "    -0.02743512 -0.17458366 -0.04841624  0.01394348 -0.09646528  0.14660512\n",
      "    -0.09159652  0.00172163  0.15161064  0.09658952  0.14109544  0.06196669\n",
      "     0.09201582  0.05076374 -0.00661731  0.09105546  0.06750521 -0.10562886\n",
      "    -0.18379067 -0.01728695]]\n",
      "\n",
      "  [[ 0.10914318  0.10920238 -0.07647859  0.06192758  0.09443278 -0.02578464\n",
      "    -0.0185346  -0.02725856  0.01710764 -0.00105562 -0.02441758  0.02913529\n",
      "    -0.08163691 -0.18825535  0.1187974  -0.08633737 -0.09158415  0.03028932\n",
      "     0.0942779  -0.06810841 -0.01051615  0.03144568  0.04537692 -0.04592071\n",
      "     0.07358568 -0.12253227 -0.08831763 -0.12934721 -0.06415671  0.06341728\n",
      "     0.13494867 -0.09671149]]\n",
      "\n",
      "  [[ 0.11624817 -0.16534075 -0.07102791 -0.03214964 -0.06368055  0.10087325\n",
      "    -0.01081072 -0.10716294  0.06120553 -0.00927599 -0.05433169  0.08000079\n",
      "     0.07788771 -0.11567886  0.03666782 -0.09512966  0.1206515   0.04340879\n",
      "     0.1024022   0.05553481 -0.04355828  0.12136971 -0.06035078 -0.01607604\n",
      "     0.1135348  -0.18364008  0.06242302  0.06506094  0.18985532  0.09266447\n",
      "     0.05134565  0.08523347]]]\n",
      "\n",
      "\n",
      " [[[ 0.03472305  0.05250109 -0.164767   -0.06608515  0.09832915 -0.05147836\n",
      "     0.12642279  0.07464287  0.08271279  0.14100847 -0.1509954   0.04532741\n",
      "     0.11205802 -0.00443882  0.0551012  -0.07360887 -0.06868927  0.08762775\n",
      "    -0.12806129 -0.04116891  0.12868427  0.06004704  0.08270691 -0.07871213\n",
      "    -0.0291302   0.04031774  0.04612682 -0.12530307 -0.09470361 -0.05405021\n",
      "     0.05193331  0.0106891 ]]\n",
      "\n",
      "  [[ 0.09055676 -0.03707043  0.0715282  -0.05163456 -0.1259266   0.07802676\n",
      "    -0.11694278  0.09132877  0.0942606   0.08013685 -0.09360576 -0.12852381\n",
      "     0.00469497  0.07616658 -0.04780069 -0.11571985  0.02436908  0.11841408\n",
      "    -0.03768761  0.03117692  0.04239678  0.07173462  0.09865082 -0.03662446\n",
      "    -0.0546242   0.00254652 -0.04609942 -0.03535186 -0.02927941 -0.01431515\n",
      "     0.00185101  0.02854172]]\n",
      "\n",
      "  [[ 0.13764884 -0.04475282  0.09552526  0.16756529 -0.04358193 -0.14365448\n",
      "    -0.10348228 -0.03857827  0.03905259 -0.05707468 -0.05887417  0.15197539\n",
      "     0.01522705  0.1411185   0.12912884 -0.18461591  0.17216228  0.08717168\n",
      "    -0.09099833  0.0010174   0.02760968  0.00588926  0.01250963 -0.03986014\n",
      "    -0.03437057  0.1591893   0.11861813 -0.05427469 -0.00160461  0.10245945\n",
      "    -0.03035483 -0.01163193]]\n",
      "\n",
      "  [[ 0.12964502  0.02546753 -0.01765358 -0.08207226  0.02663263  0.07204982\n",
      "     0.07659836 -0.11295985 -0.10446836  0.06957905 -0.0860102   0.02402759\n",
      "     0.05343829 -0.11656006  0.00351309  0.01765902  0.0422703  -0.12581848\n",
      "     0.04272262 -0.01917074 -0.0593912   0.01534583  0.16360369 -0.02086404\n",
      "     0.07490868 -0.0081506   0.07961745  0.06119735 -0.07416164  0.01452781\n",
      "    -0.13657455 -0.04921152]]\n",
      "\n",
      "  [[-0.0670407  -0.08281762  0.01968372  0.10305786 -0.12234026 -0.16746274\n",
      "     0.11200108 -0.06428304 -0.06024376 -0.11553222 -0.1423692  -0.06998336\n",
      "    -0.10849237  0.01247156 -0.06869031  0.03798836  0.19981645 -0.06648053\n",
      "    -0.12890814  0.00261362  0.00100165  0.07040895  0.12839222  0.04402812\n",
      "     0.05996179  0.14960304 -0.03179953 -0.18907994  0.10299305  0.04940651\n",
      "    -0.00538911  0.04365529]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "zx2 = tf.constant([1,2,3],shape=[3])\n",
    "zx3 = tf.random_normal(shape=[3, 3])\n",
    "print sess.run(zx3)\n",
    "zx4 = tf.truncated_normal([5, 5, 1, 32], stddev=0.1)\n",
    "print zx4.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
